{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Based Movie Recommendations\n",
    "Andrea Pagotto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook will explain implementation and experimentations done on the Movie Lens dataset, downloaded through Kaggle (\"The Movies Dataset\"). The dataset consists of several different csv files, containing different types of information about the movies including, identification numbers for imdb and tmdb, metadata about the cast and crew, descriptions of the movies, keywords and more. The main features of the data focussed on in this notebook will be the text data: descriptions, keywords, and metadata. Using this data, as well as data about user ratings for each movie, recommendation techniques will be experimented with. \n",
    "\n",
    "The main recommendation approaches being assessed are:\n",
    "- content based recommendations to identify similar movies\n",
    "- content based recommendations for a particular user\n",
    "- classic collaborative filtering\n",
    "- a hybrid approach\n",
    "\n",
    "First, the notebook will show how to load and format data to prepare for use in similarity comparisons. Next, the notebook will show how to represent text features in different ways including tfidf representations and word embeddings. Finally, this notebook will show how to use these features to generate movie similarity rankings for different types of recommenders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First will load the required pakages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from surprise import Reader, Dataset, SVD, evaluate\n",
    "from scipy import spatial\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "# import custom functions\n",
    "import nlpProjectFunctions\n",
    "from nlpProjectFunctions import get_director, convert_int\n",
    "\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data and Formatting with Pandas\n",
    "Generate a data frame from the full dataset, then restrict the size to only the movies present in the smaller dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load all datasets\n",
    "md = pd. read_csv('the-movies-dataset/movies_metadata.csv')\n",
    "links_small = pd.read_csv('the-movies-dataset/links_small.csv')\n",
    "credits = pd.read_csv('the-movies-dataset/credits.csv')\n",
    "keywords = pd.read_csv('the-movies-dataset/keywords.csv')\n",
    "ratings = pd.read_csv('the-movies-dataset/ratings_small.csv')\n",
    "# Create a mapping from the small links dataset\n",
    "id_map = pd.read_csv('the-movies-dataset/links_small.csv')[['movieId', 'tmdbId']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format the full dataset into a panda dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>year</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>[{'cast_id': 14, 'character': 'Woody (voice)',...</td>\n",
       "      <td>[{'credit_id': '52fe4284c3a36847f8024f49', 'de...</td>\n",
       "      <td>[{'id': 931, 'name': 'jealousy'}, {'id': 4290,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[Adventure, Fantasy, Family]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'Alan Parrish', '...</td>\n",
       "      <td>[{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...</td>\n",
       "      <td>[{'id': 10090, 'name': 'board game'}, {'id': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Romance, Comedy]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>[{'cast_id': 2, 'character': 'Max Goldman', 'c...</td>\n",
       "      <td>[{'credit_id': '52fe466a9251416c75077a89', 'de...</td>\n",
       "      <td>[{'id': 1495, 'name': 'fishing'}, {'id': 12392...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000000</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Friends are the people who let you be yourself...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>False</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>[{'cast_id': 1, 'character': \"Savannah 'Vannah...</td>\n",
       "      <td>[{'credit_id': '52fe44779251416c91011acb', 'de...</td>\n",
       "      <td>[{'id': 818, 'name': 'based on novel'}, {'id':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>False</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'George Banks', '...</td>\n",
       "      <td>[{'credit_id': '52fe44959251416c75039ed7', 'de...</td>\n",
       "      <td>[{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "3  False                                                NaN  16000000   \n",
       "4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
       "\n",
       "                         genres                              homepage     id  \\\n",
       "0   [Animation, Comedy, Family]  http://toystory.disney.com/toy-story    862   \n",
       "1  [Adventure, Fantasy, Family]                                   NaN   8844   \n",
       "2             [Romance, Comedy]                                   NaN  15602   \n",
       "3      [Comedy, Drama, Romance]                                   NaN  31357   \n",
       "4                      [Comedy]                                   NaN  11862   \n",
       "\n",
       "     imdb_id original_language               original_title  \\\n",
       "0  tt0114709                en                    Toy Story   \n",
       "1  tt0113497                en                      Jumanji   \n",
       "2  tt0113228                en             Grumpier Old Men   \n",
       "3  tt0114885                en            Waiting to Exhale   \n",
       "4  tt0113041                en  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...   \n",
       "1  When siblings Judy and Peter discover an encha...   \n",
       "2  A family wedding reignites the ancient feud be...   \n",
       "3  Cheated on, mistreated and stepped on, the wom...   \n",
       "4  Just when George Banks has recovered from his ...   \n",
       "\n",
       "                         ...                            status  \\\n",
       "0                        ...                          Released   \n",
       "1                        ...                          Released   \n",
       "2                        ...                          Released   \n",
       "3                        ...                          Released   \n",
       "4                        ...                          Released   \n",
       "\n",
       "                                             tagline  \\\n",
       "0                                                NaN   \n",
       "1          Roll the dice and unleash the excitement!   \n",
       "2  Still Yelling. Still Fighting. Still Ready for...   \n",
       "3  Friends are the people who let you be yourself...   \n",
       "4  Just When His World Is Back To Normal... He's ...   \n",
       "\n",
       "                         title  video vote_average  vote_count  year  \\\n",
       "0                    Toy Story  False          7.7      5415.0  1995   \n",
       "1                      Jumanji  False          6.9      2413.0  1995   \n",
       "2             Grumpier Old Men  False          6.5        92.0  1995   \n",
       "3            Waiting to Exhale  False          6.1        34.0  1995   \n",
       "4  Father of the Bride Part II  False          5.7       173.0  1995   \n",
       "\n",
       "                                                cast  \\\n",
       "0  [{'cast_id': 14, 'character': 'Woody (voice)',...   \n",
       "1  [{'cast_id': 1, 'character': 'Alan Parrish', '...   \n",
       "2  [{'cast_id': 2, 'character': 'Max Goldman', 'c...   \n",
       "3  [{'cast_id': 1, 'character': \"Savannah 'Vannah...   \n",
       "4  [{'cast_id': 1, 'character': 'George Banks', '...   \n",
       "\n",
       "                                                crew  \\\n",
       "0  [{'credit_id': '52fe4284c3a36847f8024f49', 'de...   \n",
       "1  [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...   \n",
       "2  [{'credit_id': '52fe466a9251416c75077a89', 'de...   \n",
       "3  [{'credit_id': '52fe44779251416c91011acb', 'de...   \n",
       "4  [{'credit_id': '52fe44959251416c75039ed7', 'de...   \n",
       "\n",
       "                                            keywords  \n",
       "0  [{'id': 931, 'name': 'jealousy'}, {'id': 4290,...  \n",
       "1  [{'id': 10090, 'name': 'board game'}, {'id': 1...  \n",
       "2  [{'id': 1495, 'name': 'fishing'}, {'id': 12392...  \n",
       "3  [{'id': 818, 'name': 'based on novel'}, {'id':...  \n",
       "4  [{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reformat the genres, id and year columns, drop some indices\n",
    "md['genres'] = md['genres'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "md['year'] = pd.to_datetime(md['release_date'], errors='coerce').apply(lambda x: str(x).split('-')[0] if x != np.nan else np.nan)\n",
    "md = md.drop([19730, 29503, 35587])\n",
    "md['id'] = md['id'].astype('int')\n",
    "\n",
    "# load key words and credits data into the md\n",
    "keywords['id'] = keywords['id'].astype('int')\n",
    "credits['id'] = credits['id'].astype('int')\n",
    "md = md.merge(credits, on='id')\n",
    "md = md.merge(keywords, on='id')\n",
    "\n",
    "md.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a subset of the data set using only the movies in the smaller dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([7353], dtype='int64')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>year</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7353</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 99606, 'name': 'Mean Girls Collection',...</td>\n",
       "      <td>17000000</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>http://www.meangirls.com/</td>\n",
       "      <td>10625</td>\n",
       "      <td>tt0377092</td>\n",
       "      <td>en</td>\n",
       "      <td>Mean Girls</td>\n",
       "      <td>Cady Heron is a hit with The Plastics, the A-l...</td>\n",
       "      <td>...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Welcome to girl world.</td>\n",
       "      <td>Mean Girls</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>[{'cast_id': 9, 'character': 'Cady Heron', 'cr...</td>\n",
       "      <td>[{'credit_id': '5635ec3092514129fe00c2f5', 'de...</td>\n",
       "      <td>[{'id': 5248, 'name': 'female friendship'}, {'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      adult                              belongs_to_collection    budget  \\\n",
       "7353  False  {'id': 99606, 'name': 'Mean Girls Collection',...  17000000   \n",
       "\n",
       "        genres                   homepage     id    imdb_id original_language  \\\n",
       "7353  [Comedy]  http://www.meangirls.com/  10625  tt0377092                en   \n",
       "\n",
       "     original_title                                           overview  \\\n",
       "7353     Mean Girls  Cady Heron is a hit with The Plastics, the A-l...   \n",
       "\n",
       "                            ...                            status  \\\n",
       "7353                        ...                          Released   \n",
       "\n",
       "                     tagline       title  video vote_average  vote_count  \\\n",
       "7353  Welcome to girl world.  Mean Girls  False          6.9      2401.0   \n",
       "\n",
       "      year                                               cast  \\\n",
       "7353  2004  [{'cast_id': 9, 'character': 'Cady Heron', 'cr...   \n",
       "\n",
       "                                                   crew  \\\n",
       "7353  [{'credit_id': '5635ec3092514129fe00c2f5', 'de...   \n",
       "\n",
       "                                               keywords  \n",
       "7353  [{'id': 5248, 'name': 'female friendship'}, {'...  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(md[md['title']=='Mean Girls'].index)\n",
    "md[md['title']=='Mean Girls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>year</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>[{'cast_id': 14, 'character': 'Woody (voice)',...</td>\n",
       "      <td>[{'credit_id': '52fe4284c3a36847f8024f49', 'de...</td>\n",
       "      <td>[{'id': 931, 'name': 'jealousy'}, {'id': 4290,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[Adventure, Fantasy, Family]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'Alan Parrish', '...</td>\n",
       "      <td>[{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...</td>\n",
       "      <td>[{'id': 10090, 'name': 'board game'}, {'id': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Romance, Comedy]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>[{'cast_id': 2, 'character': 'Max Goldman', 'c...</td>\n",
       "      <td>[{'credit_id': '52fe466a9251416c75077a89', 'de...</td>\n",
       "      <td>[{'id': 1495, 'name': 'fishing'}, {'id': 12392...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000000</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Friends are the people who let you be yourself...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>False</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>[{'cast_id': 1, 'character': \"Savannah 'Vannah...</td>\n",
       "      <td>[{'credit_id': '52fe44779251416c91011acb', 'de...</td>\n",
       "      <td>[{'id': 818, 'name': 'based on novel'}, {'id':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>False</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'George Banks', '...</td>\n",
       "      <td>[{'credit_id': '52fe44959251416c75039ed7', 'de...</td>\n",
       "      <td>[{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "3  False                                                NaN  16000000   \n",
       "4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
       "\n",
       "                         genres                              homepage     id  \\\n",
       "0   [Animation, Comedy, Family]  http://toystory.disney.com/toy-story    862   \n",
       "1  [Adventure, Fantasy, Family]                                   NaN   8844   \n",
       "2             [Romance, Comedy]                                   NaN  15602   \n",
       "3      [Comedy, Drama, Romance]                                   NaN  31357   \n",
       "4                      [Comedy]                                   NaN  11862   \n",
       "\n",
       "     imdb_id original_language               original_title  \\\n",
       "0  tt0114709                en                    Toy Story   \n",
       "1  tt0113497                en                      Jumanji   \n",
       "2  tt0113228                en             Grumpier Old Men   \n",
       "3  tt0114885                en            Waiting to Exhale   \n",
       "4  tt0113041                en  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...   \n",
       "1  When siblings Judy and Peter discover an encha...   \n",
       "2  A family wedding reignites the ancient feud be...   \n",
       "3  Cheated on, mistreated and stepped on, the wom...   \n",
       "4  Just when George Banks has recovered from his ...   \n",
       "\n",
       "                         ...                            status  \\\n",
       "0                        ...                          Released   \n",
       "1                        ...                          Released   \n",
       "2                        ...                          Released   \n",
       "3                        ...                          Released   \n",
       "4                        ...                          Released   \n",
       "\n",
       "                                             tagline  \\\n",
       "0                                                NaN   \n",
       "1          Roll the dice and unleash the excitement!   \n",
       "2  Still Yelling. Still Fighting. Still Ready for...   \n",
       "3  Friends are the people who let you be yourself...   \n",
       "4  Just When His World Is Back To Normal... He's ...   \n",
       "\n",
       "                         title  video vote_average  vote_count  year  \\\n",
       "0                    Toy Story  False          7.7      5415.0  1995   \n",
       "1                      Jumanji  False          6.9      2413.0  1995   \n",
       "2             Grumpier Old Men  False          6.5        92.0  1995   \n",
       "3            Waiting to Exhale  False          6.1        34.0  1995   \n",
       "4  Father of the Bride Part II  False          5.7       173.0  1995   \n",
       "\n",
       "                                                cast  \\\n",
       "0  [{'cast_id': 14, 'character': 'Woody (voice)',...   \n",
       "1  [{'cast_id': 1, 'character': 'Alan Parrish', '...   \n",
       "2  [{'cast_id': 2, 'character': 'Max Goldman', 'c...   \n",
       "3  [{'cast_id': 1, 'character': \"Savannah 'Vannah...   \n",
       "4  [{'cast_id': 1, 'character': 'George Banks', '...   \n",
       "\n",
       "                                                crew  \\\n",
       "0  [{'credit_id': '52fe4284c3a36847f8024f49', 'de...   \n",
       "1  [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...   \n",
       "2  [{'credit_id': '52fe466a9251416c75077a89', 'de...   \n",
       "3  [{'credit_id': '52fe44779251416c91011acb', 'de...   \n",
       "4  [{'credit_id': '52fe44959251416c75039ed7', 'de...   \n",
       "\n",
       "                                            keywords  \n",
       "0  [{'id': 931, 'name': 'jealousy'}, {'id': 4290,...  \n",
       "1  [{'id': 10090, 'name': 'board game'}, {'id': 1...  \n",
       "2  [{'id': 1495, 'name': 'fishing'}, {'id': 12392...  \n",
       "3  [{'id': 818, 'name': 'based on novel'}, {'id':...  \n",
       "4  [{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to use a subset of the data, restrict the full data to only \n",
    "# the movies in the smaller dataset\n",
    "links_small = links_small[links_small['tmdbId'].notnull()]['tmdbId'].astype('int')\n",
    "\n",
    "# for each id in the links dataset, extract that indice\n",
    "smd = md[md['id'].isin(links_small)]\n",
    "smd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data for Description Based Recommender\n",
    "\n",
    "First format the text in the text-containing columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>year</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>keywords</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>[{'cast_id': 14, 'character': 'Woody (voice)',...</td>\n",
       "      <td>[{'credit_id': '52fe4284c3a36847f8024f49', 'de...</td>\n",
       "      <td>[{'id': 931, 'name': 'jealousy'}, {'id': 4290,...</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[Adventure, Fantasy, Family]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>...</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'Alan Parrish', '...</td>\n",
       "      <td>[{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...</td>\n",
       "      <td>[{'id': 10090, 'name': 'board game'}, {'id': 1...</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Romance, Comedy]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>...</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>[{'cast_id': 2, 'character': 'Max Goldman', 'c...</td>\n",
       "      <td>[{'credit_id': '52fe466a9251416c75077a89', 'de...</td>\n",
       "      <td>[{'id': 1495, 'name': 'fishing'}, {'id': 12392...</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000000</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>...</td>\n",
       "      <td>Friends are the people who let you be yourself...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>False</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>[{'cast_id': 1, 'character': \"Savannah 'Vannah...</td>\n",
       "      <td>[{'credit_id': '52fe44779251416c91011acb', 'de...</td>\n",
       "      <td>[{'id': 818, 'name': 'based on novel'}, {'id':...</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>...</td>\n",
       "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>False</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'George Banks', '...</td>\n",
       "      <td>[{'credit_id': '52fe44959251416c75039ed7', 'de...</td>\n",
       "      <td>[{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  adult                              belongs_to_collection    budget  \\\n",
       "0      0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1      1  False                                                NaN  65000000   \n",
       "2      2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "3      3  False                                                NaN  16000000   \n",
       "4      4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
       "\n",
       "                         genres                              homepage     id  \\\n",
       "0   [Animation, Comedy, Family]  http://toystory.disney.com/toy-story    862   \n",
       "1  [Adventure, Fantasy, Family]                                   NaN   8844   \n",
       "2             [Romance, Comedy]                                   NaN  15602   \n",
       "3      [Comedy, Drama, Romance]                                   NaN  31357   \n",
       "4                      [Comedy]                                   NaN  11862   \n",
       "\n",
       "     imdb_id original_language               original_title  \\\n",
       "0  tt0114709                en                    Toy Story   \n",
       "1  tt0113497                en                      Jumanji   \n",
       "2  tt0113228                en             Grumpier Old Men   \n",
       "3  tt0114885                en            Waiting to Exhale   \n",
       "4  tt0113041                en  Father of the Bride Part II   \n",
       "\n",
       "                         ...                          \\\n",
       "0                        ...                           \n",
       "1                        ...                           \n",
       "2                        ...                           \n",
       "3                        ...                           \n",
       "4                        ...                           \n",
       "\n",
       "                                             tagline  \\\n",
       "0                                                      \n",
       "1          Roll the dice and unleash the excitement!   \n",
       "2  Still Yelling. Still Fighting. Still Ready for...   \n",
       "3  Friends are the people who let you be yourself...   \n",
       "4  Just When His World Is Back To Normal... He's ...   \n",
       "\n",
       "                         title  video vote_average vote_count  year  \\\n",
       "0                    Toy Story  False          7.7     5415.0  1995   \n",
       "1                      Jumanji  False          6.9     2413.0  1995   \n",
       "2             Grumpier Old Men  False          6.5       92.0  1995   \n",
       "3            Waiting to Exhale  False          6.1       34.0  1995   \n",
       "4  Father of the Bride Part II  False          5.7      173.0  1995   \n",
       "\n",
       "                                                cast  \\\n",
       "0  [{'cast_id': 14, 'character': 'Woody (voice)',...   \n",
       "1  [{'cast_id': 1, 'character': 'Alan Parrish', '...   \n",
       "2  [{'cast_id': 2, 'character': 'Max Goldman', 'c...   \n",
       "3  [{'cast_id': 1, 'character': \"Savannah 'Vannah...   \n",
       "4  [{'cast_id': 1, 'character': 'George Banks', '...   \n",
       "\n",
       "                                                crew  \\\n",
       "0  [{'credit_id': '52fe4284c3a36847f8024f49', 'de...   \n",
       "1  [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...   \n",
       "2  [{'credit_id': '52fe466a9251416c75077a89', 'de...   \n",
       "3  [{'credit_id': '52fe44779251416c91011acb', 'de...   \n",
       "4  [{'credit_id': '52fe44959251416c75039ed7', 'de...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [{'id': 931, 'name': 'jealousy'}, {'id': 4290,...   \n",
       "1  [{'id': 10090, 'name': 'board game'}, {'id': 1...   \n",
       "2  [{'id': 1495, 'name': 'fishing'}, {'id': 12392...   \n",
       "3  [{'id': 818, 'name': 'based on novel'}, {'id':...   \n",
       "4  [{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...   \n",
       "\n",
       "                                         description  \n",
       "0  Led by Woody, Andy's toys live happily in his ...  \n",
       "1  When siblings Judy and Peter discover an encha...  \n",
       "2  A family wedding reignites the ancient feud be...  \n",
       "3  Cheated on, mistreated and stepped on, the wom...  \n",
       "4  Just when George Banks has recovered from his ...  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process the tagline column, and create a description column\n",
    "smd['tagline'] = smd['tagline'].fillna('')\n",
    "smd['description'] = smd['overview'] + smd['tagline']\n",
    "smd['description'] = smd['description'].fillna('')\n",
    "\n",
    "smd = smd.reset_index() \n",
    "smd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([5207], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(smd[smd['title']=='Mean Girls'].index)\n",
    "# note the index for this movie has changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data for Metadata Recommender\n",
    "Format the columns containing metadata to be able to extract words for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smd['keywords'] = smd['keywords'].apply(literal_eval)\n",
    "smd['crew'] = smd['crew'].apply(literal_eval)\n",
    "smd['cast'] = smd['cast'].apply(literal_eval)\n",
    "\n",
    "smd['cast_size'] = smd['cast'].apply(lambda x: len(x))\n",
    "smd['crew_size'] = smd['crew'].apply(lambda x: len(x))\n",
    "\n",
    "smd['director'] = smd['crew'].apply(get_director)\n",
    "smd['cast'] = smd['cast'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "smd['cast'] = smd['cast'].apply(lambda x: x[:3] if len(x) >=3 else x)\n",
    "smd['keywords'] = smd['keywords'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "smd['cast'] = smd['cast'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])\n",
    "smd['director'] = smd['director'].astype('str').apply(lambda x: str.lower(x.replace(\" \", \"\")))\n",
    "smd['director'] = smd['director'].apply(lambda x: [x,x, x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing Keywords and Metadata into One\n",
    "Creating a new column to contain all the relevant data from the metadata as a bag of features, called \"soup\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "independent film        610\n",
      "woman director          550\n",
      "murder                  399\n",
      "duringcreditsstinger    327\n",
      "based on novel          318\n",
      "Name: keyword, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# requires s that is defined below\n",
    "def filter_keywords(x):\n",
    "    words = []\n",
    "    for i in x:\n",
    "        if i in s:\n",
    "            words.append(i)\n",
    "    return words\n",
    "\n",
    "# s is a reduced list of keywords, with only the eywords that occur more than once\n",
    "s = smd.apply(lambda x: pd.Series(x['keywords']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'keyword'\n",
    "s = s.value_counts()\n",
    "print(s[:5])\n",
    "s = s[s > 1]\n",
    "\n",
    "# create a stemmer \n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "# process words using filter and stemmer\n",
    "smd['keywords'] = smd['keywords'].apply(filter_keywords)\n",
    "smd['keywords'] = smd['keywords'].apply(lambda x: [stemmer.stem(i) for i in x])\n",
    "smd['keywords'] = smd['keywords'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])\n",
    "\n",
    "# create a soup column to contain all processed metadata words\n",
    "smd['soup'] = smd['keywords'] + smd['cast'] + smd['director'] + smd['genres']\n",
    "smd['soup'] = smd['soup'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "smd = smd.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9219, 35)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Mappings\n",
    "\n",
    "Create mappings to access different information given title or id. Note there are three different ids associated with each movie: its index in the dataset, the imdb id, and the tmdb id. The ratings dataset only has the imdb and tmdb ids, no titles, so it is necessary to be able to access movies from each of these ids, so mappings will be made to allow this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Addams Family Index:\n",
      "1701\n",
      "Dracula Index:\n",
      "title\n",
      "Dracula    1100\n",
      "Dracula    2135\n",
      "Dracula    4797\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a title to index mapping, so indices for \n",
    "# a title can be found.\n",
    "# Note smd.index is just its position in the small dataset\n",
    "# smd.index will be the index of this item in arrays\n",
    "titles = smd['title']\n",
    "title2index = pd.Series(smd.index, index=titles)\n",
    "#print(indices.head())\n",
    "\n",
    "# indices can be accessed from the title, but note it\n",
    "# returns multiple items when the titles occurs more \n",
    "# than once like in the movie dracula\n",
    "print(\"The Addams Family Index:\")\n",
    "print(title2index.loc['The Addams Family'])\n",
    "print(\"Dracula Index:\")\n",
    "print(title2index.loc['Dracula'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the titles can occur more than once in the dataset resulting in inconsistent return values, the movies will instead be access by their ids, as these ids are unique within the dataset. To do this more mappings will be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100     6114\n",
      "2135      138\n",
      "4797    33521\n",
      "Name: id, dtype: int64\n",
      "1701    2907\n",
      "Name: id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the ids for the previous movies\n",
    "print(smd[smd['title'] == 'Dracula']['id'])\n",
    "print(smd[smd['title'] == 'The Addams Family']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie 6114 (Dracula) Index:\n",
      "1100\n",
      "Movie 2907 (Addams Family) Index:\n",
      "1701\n"
     ]
    }
   ],
   "source": [
    "# Map the ids to the index same as done with titles\n",
    "# 'id' is the tmdb ids in metadata and small links data\n",
    "# this id can be mapped to index, which will be the index of\n",
    "# the movie in an array, in later functions\n",
    "ids = smd['id']\n",
    "id2index = pd.Series(smd.index, index=ids)\n",
    "print(\"Movie 6114 (Dracula) Index:\")\n",
    "print(id2index.loc[6114])\n",
    "print(\"Movie 2907 (Addams Family) Index:\")\n",
    "print(id2index.loc[2907])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next because the ratings dataset contains only the \"movie id\" ids, create mappings between the currently used tmdb ids and these ids. The small links dataset contains all three ids, and the metadata datset only contains the tmdb and imdb ids. The column 'id' in the metadata datset corresponds to 'tmdb id' in the small links dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             movieId     id\n",
      "title                                      \n",
      "Toy Story                          1    862\n",
      "Jumanji                            2   8844\n",
      "Grumpier Old Men                   3  15602\n",
      "Waiting to Exhale                  4  31357\n",
      "Father of the Bride Part II        5  11862\n"
     ]
    }
   ],
   "source": [
    "# id map will map the movie id needed for the \n",
    "# ratings data to the tmdbId, and title\n",
    "id_map['tmdbId'] = id_map['tmdbId'].apply(convert_int)\n",
    "id_map.columns = ['movieId', 'id']\n",
    "\n",
    "# The index is currently being set to title, however do to non unique titles\n",
    "# an alternative version of the mapping will be made\n",
    "id_map = id_map.merge(smd[['title', 'id']], on='id').set_index('title')\n",
    "#id_map = id_map.set_index('tmdbId')\n",
    "\n",
    "print(id_map.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Toy Story'], dtype='object', name='title')\n",
      "           movieId   id\n",
      "title                  \n",
      "Toy Story        1  862\n"
     ]
    }
   ],
   "source": [
    "# example how to access a title from an index with this mapping\n",
    "title = id_map[id_map['id']==862].index\n",
    "print(id_map[id_map['id']==862].index)\n",
    "\n",
    "# how to access ids for a certain title\n",
    "print(id_map.loc[title])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of this mapping will print the tmdb id and movie id (in the ratings dataset) for a given title). Next we will make a mapping that is indexed by the movie id instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id\n",
      "movieId       \n",
      "1          862\n",
      "2         8844\n",
      "3        15602\n",
      "4        31357\n",
      "5        11862\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Tmdb id for movie id 1339:\n",
      "6114.0\n",
      "         movieId\n",
      "id              \n",
      "862.0          1\n",
      "8844.0         2\n",
      "15602.0        3\n",
      "31357.0        4\n",
      "11862.0        5\n",
      "movie id for tmdb id 6114:\n",
      "1339\n",
      "Tmdb id for movie id 1339:\n",
      "Float64Index([6114.0], dtype='float64', name='id')\n"
     ]
    }
   ],
   "source": [
    "movieid_map = id_map.set_index('movieId')\n",
    "print(movieid_map.head())\n",
    "print(type(movieid_map))\n",
    "# retrieve a tmdb id from movieId 1339\n",
    "print(\"Tmdb id for movie id 1339:\")\n",
    "print(movieid_map.loc[1339]['id'])\n",
    "\n",
    "tmdb_map = id_map.set_index('id')\n",
    "print(tmdb_map.head())\n",
    "\n",
    "# retrieve a movieId from a tmdb id 6114\n",
    "print(\"movie id for tmdb id 6114:\")\n",
    "print(tmdb_map.loc[6114]['movieId'])\n",
    "\n",
    "# how to use this map in the reverse direction\n",
    "print(\"Tmdb id for movie id 1339:\")\n",
    "print(tmdb_map[tmdb_map['movieId']==1339].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "862.0      1\n",
      "8844.0     2\n",
      "15602.0    3\n",
      "31357.0    4\n",
      "11862.0    5\n",
      "Name: movieId, dtype: int64\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "movieIds = tmdb_map['movieId']\n",
    "print(movieIds.head())\n",
    "\n",
    "# a way to check if a movie id is in the dataset\n",
    "print(55207 in movieid_map.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These mappings will be used in the upcoming functions to retrieve information about the movies as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data with User Ratings\n",
    "\n",
    "This code will use the ratings dataset, and use a reader to read it into a dataset format for use in the recommender functions. Also, it will use a built in function to generate splits for cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reader = Reader()\n",
    "ratings.head()\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "data.split(n_folds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Representations\n",
    "\n",
    "This section will implement and experiment with word represetations to prepare for use in generating features from the text data. In particular, this section will focus on representing words with word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Tokens\n",
    "\n",
    "The first step in representing text, is to tokenize the texts. This process will create a list of \"tokens\" which in this case will just be words. To do this, will will create a custom tokenization function that will apply all necessary processing to the raw text descriptions. This function is shown in the following code. This function will tokenize using the regex expression for words, then it will transform all the words to lower case and remove stop words, as well as single characters. The last step of the preprocessing will remove numbers, to result in only words remaining for the word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumanji\n",
      "['siblings', 'judy', 'peter', 'discover', 'enchanted', 'board', 'game', 'opens', 'door', 'magical', 'world', 'unwittingly', 'invite', 'alan', 'adult', 'trapped', 'inside', 'game', 'years', 'living', 'room', 'alan', 'hope', 'freedom', 'finish', 'game', 'proves', 'risky', 'three', 'find', 'running', 'giant', 'rhinoceroses', 'evil', 'monkeys', 'terrifying', 'creatures', 'roll', 'dice', 'unleash', 'excitement']\n",
      "9219\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokenized = tokenizer.tokenize(text)\n",
    "    mod = [w.lower() for w in tokenized if len(w) > 1 and w.lower() not in stopwords.words('english')]\n",
    "    words = [w for w in mod if not w.isnumeric()]\n",
    "    return  words\n",
    "\n",
    "# apply the tokenizer to the descriptions\n",
    "tokens = smd['description'].apply(tokenize)\n",
    "\n",
    "# print a sample of a tokenized description and the associated movie title\n",
    "print(titles[1])\n",
    "print(tokens[1])\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Word Embeddings - GloVe\n",
    "\n",
    "Once the text is in tokenized form, word embeddings can be applied. In order to do this, first a dictionary of word embeddings must be loaded from a text file and processed into the right format to be able to look up words as a python dictionary. Pre-trained word embeddings will be loaded that were trained useing the GloVe algorithm. After these vectors are loaded they will be evaulated to assess that they are produce meaningful results. This evalution procedure can be used as part of the assessement towards determining which wod embeddings should be used for a particular application, and comparisons can be done with other word vectors, such as google word2vec.\n",
    "\n",
    "#### Loading Pretrained Vectors\n",
    "\n",
    "The first step in the procedure is to load the glove text file and format it into dictionaries. Mappings are made between word indices in both directions, and also between words and their embedding vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get vocab and create dict with vocab indexes\n",
    "glove_file = 'glove.6B.50d.txt'\n",
    "with open(glove_file, 'r') as f:\n",
    "    words = [x.rstrip().split(' ')[0] for x in f.readlines()]\n",
    "\n",
    "vocab_size = len(words)\n",
    "vocab = {w: idx for idx, w in enumerate(words)}\n",
    "ivocab = {idx: w for idx, w in enumerate(words)}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code will create the mapping between the words and their embedding as a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "The word 'hello':\n",
      "[-0.38497001  0.80092001  0.064106   -0.28354999 -0.026759   -0.34531999\n",
      " -0.64253002 -0.11729    -0.33256999  0.55242997 -0.087813    0.90350002\n",
      "  0.47102001  0.56656998  0.69849998 -0.35229    -0.86541998  0.90573001\n",
      "  0.03576    -0.071705   -0.12327     0.54922998  0.47005001  0.35572001\n",
      "  1.26110005 -0.67580998 -0.94983     0.68665999  0.38710001 -1.34920001\n",
      "  0.63511997  0.46416    -0.48813999  0.83827001 -0.92460001 -0.33722001\n",
      "  0.53741002 -1.06159997 -0.081403   -0.67110997  0.30923    -0.39230001\n",
      " -0.55001998 -0.68826997  0.58048999 -0.11626     0.013139   -0.57653999\n",
      "  0.048833    0.67203999]\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to create word embeddings \n",
    "embeddings_index = {}\n",
    "\n",
    "# using the glove text file once again to load the vectors\n",
    "f = open(glove_file)\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "# print a sample of one array representing a word \n",
    "print(\"The word 'hello':\")\n",
    "print(embeddings_index['hello'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the embeddings:\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "vector_dim = len(embeddings_index['hello'])\n",
    "print(\"Dimensions of the embeddings:\")\n",
    "print(vector_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen the word hello is represented as a 50 dimension numpy array. Loading a different file can change this, as the GloVe pretrained embeddings are available in various dimensions.\n",
    "\n",
    "#### Experimenting with Word Representations\n",
    "\n",
    "Before proceding with the process of generating document vectors, first we will inspect the results of the loaded glove word embeddings. We can compare the similarities between words using the cosine distance and make sure they are being properly represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store all the word embeddings in a numpy array\n",
    "# Each embedding can still be access from the array\n",
    "# using the word index in the vocab mapping dictionary\n",
    "W = np.zeros((vocab_size, vector_dim))\n",
    "for word, v in embeddings_index.items():\n",
    "    if word == '<unk>':\n",
    "        continue\n",
    "    # the word vector is stored at its index in vocab\n",
    "    W[vocab[word], :] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create a normalized version of this embedding matrix, which is the equivalient of mapping each vector to its projection on a unit hypersphere, ie. reducing the length of each vector to one, in order to only have variance between words in the angles of the vectors. This will come in handy when measuring cosine distances between words, as will be explained in the following sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize each word vector to unit variance\n",
    "W_norm = np.zeros(W.shape)\n",
    "d = (np.sum(W ** 2, 1) ** (0.5))\n",
    "W_norm = (W.T / d).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These GloVe vectors are evaluated with some benchmark testing function provided by the creators of GloVe. This can give an indication that the GloVe vectors being used are properly representing words as they should. The evaluation is done by using the GloVe vectors to guess the answers to questions in various files, using lists of given words. The accuracy of the predicting the correct answer is shown, and higher accuracies would indicate a better vector. This can be used as a way to compare different embeddings being used. It would be expected that embeddings that perform better with this evaluation would also perform better for use in the desired application. However for specific applications this can be tested to see if this evlaution method does correspond to the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- normalized vector results: -----\n",
      "capital-common-countries.txt:\n",
      "ACCURACY TOP1: 79.25% (401/506)\n",
      "capital-world.txt:\n",
      "ACCURACY TOP1: 68.48% (3098/4524)\n",
      "currency.txt:\n",
      "ACCURACY TOP1: 8.31% (72/866)\n",
      "city-in-state.txt:\n",
      "ACCURACY TOP1: 15.32% (378/2467)\n",
      "family.txt:\n",
      "ACCURACY TOP1: 68.97% (349/506)\n",
      "gram1-adjective-to-adverb.txt:\n",
      "ACCURACY TOP1: 15.22% (151/992)\n",
      "gram2-opposite.txt:\n",
      "ACCURACY TOP1: 9.48% (77/812)\n",
      "gram3-comparative.txt:\n",
      "ACCURACY TOP1: 51.80% (690/1332)\n",
      "gram4-superlative.txt:\n",
      "ACCURACY TOP1: 28.61% (321/1122)\n",
      "gram5-present-participle.txt:\n",
      "ACCURACY TOP1: 41.57% (439/1056)\n",
      "gram6-nationality-adjective.txt:\n",
      "ACCURACY TOP1: 85.99% (1375/1599)\n",
      "gram7-past-tense.txt:\n",
      "ACCURACY TOP1: 37.50% (585/1560)\n",
      "gram8-plural.txt:\n",
      "ACCURACY TOP1: 59.91% (798/1332)\n",
      "gram9-plural-verbs.txt:\n",
      "ACCURACY TOP1: 34.37% (299/870)\n",
      "Questions seen/total: 100.00% (19544/19544)\n",
      "Semantic accuracy: 48.46%  (4298/8869)\n",
      "Syntactic accuracy: 44.36%  (4735/10675)\n",
      "Total accuracy: 46.22%  (9033/19544)\n",
      "---- original vector results: ----\n",
      "capital-common-countries.txt:\n",
      "ACCURACY TOP1: 58.50% (296/506)\n",
      "capital-world.txt:\n",
      "ACCURACY TOP1: 32.12% (1453/4524)\n",
      "currency.txt:\n",
      "ACCURACY TOP1: 8.08% (70/866)\n",
      "city-in-state.txt:\n",
      "ACCURACY TOP1: 6.53% (161/2467)\n",
      "family.txt:\n",
      "ACCURACY TOP1: 34.78% (176/506)\n",
      "gram1-adjective-to-adverb.txt:\n",
      "ACCURACY TOP1: 0.60% (6/992)\n",
      "gram2-opposite.txt:\n",
      "ACCURACY TOP1: 0.62% (5/812)\n",
      "gram3-comparative.txt:\n",
      "ACCURACY TOP1: 8.93% (119/1332)\n",
      "gram4-superlative.txt:\n",
      "ACCURACY TOP1: 2.85% (32/1122)\n",
      "gram5-present-participle.txt:\n",
      "ACCURACY TOP1: 7.58% (80/1056)\n",
      "gram6-nationality-adjective.txt:\n",
      "ACCURACY TOP1: 69.17% (1106/1599)\n",
      "gram7-past-tense.txt:\n",
      "ACCURACY TOP1: 8.27% (129/1560)\n",
      "gram8-plural.txt:\n",
      "ACCURACY TOP1: 26.35% (351/1332)\n",
      "gram9-plural-verbs.txt:\n",
      "ACCURACY TOP1: 1.49% (13/870)\n",
      "Questions seen/total: 100.00% (19544/19544)\n",
      "Semantic accuracy: 24.31%  (2156/8869)\n",
      "Syntactic accuracy: 17.25%  (1841/10675)\n",
      "Total accuracy: 20.45%  (3997/19544)\n"
     ]
    }
   ],
   "source": [
    "# Use GloVe evaluation methods to verify vectors\n",
    "# perform a comparison betwen the regular length and\n",
    "# normalized vectors\n",
    "from evaluate import evaluate_vectors\n",
    "print(\"---- normalized vector results: -----\")\n",
    "evaluate_vectors(W_norm, vocab, ivocab)\n",
    "\n",
    "print(\"---- original vector results: ----\")\n",
    "evaluate_vectors(W, vocab, ivocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the normalized vector results are performing better. The next thing to note is that the definition of the cosine distance is a dot product of vectors, normalized by the distance. This will be explained in further details in coming sections. \n",
    "\n",
    "For efficiency, the cosine similarities are often calulated without normalizing by the vector length. Therefore we will compare the word similarities using the normalized and full length vectors. In the results below, it can be seen that the results are similar though there are differences. Since this is not a quantitative method of evaluation it is not easy to say which word similarities are better, however since the technical definintion of cosine distance relies on normalized vectors it would be advisable to normalize the vectors, but also keep in mind that both ways could be tested to see the effects on the results for a given application. Perhaps in some cases preserving the length of the vectors would be desirable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- original vector results: -----\n",
      "Word: king  Position in vocabulary: 691\n",
      "\n",
      "                               Word       Cosine distance\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "                            emperor\t\t5.061746\n",
      "\n",
      "                             throne\t\t4.344266\n",
      "\n",
      "                                son\t\t4.295550\n",
      "\n",
      "                               lord\t\t4.223305\n",
      "\n",
      "                             prince\t\t4.186335\n",
      "\n",
      "                                 ii\t\t4.087398\n",
      "\n",
      "                              queen\t\t4.070626\n",
      "\n",
      "                            dynasty\t\t3.983273\n",
      "\n",
      "                            kingdom\t\t3.959915\n",
      "\n",
      "                              ruler\t\t3.938324\n",
      "\n",
      "---- normalized vector results: -----\n",
      "Word: king  Position in vocabulary: 691\n",
      "\n",
      "                               Word       Cosine distance\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "                             prince\t\t0.823618\n",
      "\n",
      "                              queen\t\t0.783904\n",
      "\n",
      "                                 ii\t\t0.774623\n",
      "\n",
      "                            emperor\t\t0.773625\n",
      "\n",
      "                                son\t\t0.766719\n",
      "\n",
      "                              uncle\t\t0.762715\n",
      "\n",
      "                            kingdom\t\t0.754216\n",
      "\n",
      "                             throne\t\t0.753991\n",
      "\n",
      "                            brother\t\t0.749241\n",
      "\n",
      "                              ruler\t\t0.743425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import distance measuring function from GloVe\n",
    "from distance2 import distance\n",
    "print(\"---- original vector results: -----\")\n",
    "distance(W, vocab, ivocab, 'king')\n",
    "print(\"---- normalized vector results: -----\")\n",
    "distance(W_norm, vocab, ivocab, 'king')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will show how to get the distance between two words. This calculation will form the basis for document comparisons to come. To do this we will use our own implemented function using the built in python cosine distance measurement to assess the difference between two words, by extracting their embedding vector from the normalized matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.783904300999\n"
     ]
    }
   ],
   "source": [
    "def calc_cosine_similarity(v1, v2):\n",
    "    return 1 - spatial.distance.cosine(v1, v2)\n",
    "\n",
    "# compare glove word embeddings\n",
    "v1 = W_norm[vocab['king'], :]\n",
    "v2 = W_norm[vocab['queen'], :]\n",
    "sim = calc_cosine_similarity(v1, v2)\n",
    "print(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that the custom function for calculating cosine similarity is producing the same result as the GloVe calculation, so it will be safe to use this for other algorithms.\n",
    "\n",
    "## Document Representations and Similarities\n",
    "\n",
    "In this next section we will build upon the previous section to generate document representations from the word embeddings for each movie. We will also present alternative ways of representing movies, using the metadata, and using a more simple approach of representing the descriptions of the movies with the \"Term Frequency - Inverse Document Frequency\" (tfidf) approach. These three different methods of representing documents will be assessed on how well they are able to identify similar movies based on these text features.\n",
    "\n",
    "### Document Embedding Vectors\n",
    "\n",
    "This section will show how to represent documents with an embedding vector and then show how to use the movie embedding to get a list of similar movies.\n",
    "\n",
    "#### Generating the Embedding Vectors\n",
    "\n",
    "Next we represent each document as a vector based on the embeddings of the words it contains. This can be done by retreiving the word embeddings for each word in the list of tokens, and then taking the centroid of these vectors to represent the document as one vector. GloVe pretrained embeddings try to optimize storing the maximum representation of words in a much lower dimensional space. To do this, we have a function called movie_vector, that will create an embedding vector for a given movie, with the input as tokens of the movie description. In order to use this function it is required to first tokenize the movie description, then get the word vectors as shown previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Girls movie vector:\n",
      "[ -4.93672053e-02   1.52430687e-01  -2.05389903e-02   2.05246823e-02\n",
      "   1.62483148e-01   1.13093878e-01  -1.49768446e-01  -5.41984829e-02\n",
      "  -6.18856759e-02   1.22158519e-02  -8.34710386e-03   9.66496158e-02\n",
      "  -1.02698110e-01   2.01688507e-02   1.08731190e-01  -1.69683162e-02\n",
      "  -5.59966195e-02   7.14464739e-02  -6.86821838e-02  -2.02682901e-02\n",
      "  -3.55507603e-02   1.17407977e-01   2.50736765e-04   1.26677554e-02\n",
      "   2.54700024e-02  -4.29726582e-01  -4.74213006e-02   2.63490900e-02\n",
      "  -4.61213273e-03  -1.72475568e-01   7.19597129e-01   5.77104464e-03\n",
      "   2.60526024e-02  -7.10883941e-03   5.98140938e-02   1.86511793e-02\n",
      "   3.62828345e-02  -4.47221975e-02   6.86866311e-02  -1.18390586e-01\n",
      "  -9.36009285e-02   5.99338586e-02  -9.12574109e-03  -1.04849536e-01\n",
      "   1.25914916e-01   8.00522571e-03  -2.91040108e-02  -1.89303337e-01\n",
      "   2.73562960e-02   6.73045993e-02]\n"
     ]
    }
   ],
   "source": [
    "# returns normalized vector rep of the movie\n",
    "# vector_dim as previously defined the dimension of one word vector\n",
    "# this function relies on previously generated data vocabs and matrices\n",
    "\n",
    "def movie_vector(W, movie_toks):\n",
    "    vec_result = np.zeros(vector_dim)\n",
    "    for idx, term in enumerate(movie_toks):\n",
    "        if term in vocab:\n",
    "            #print('Word: %s  Position in vocabulary: %i' % (term, vocab[term]))\n",
    "            if idx == 0:\n",
    "                vec_result = np.copy(W[vocab[term], :])\n",
    "            else:\n",
    "                vec_result += W[vocab[term], :] \n",
    "        else:\n",
    "            #print('Word: %s  Out of dictionary!\\n' % term)\n",
    "            continue\n",
    "    \n",
    "    vec_norm = np.zeros(vec_result.shape)\n",
    "    d = (np.sum(vec_result ** 2,) ** (0.5))\n",
    "    if d > 0:\n",
    "        vec_norm = (vec_result.T / d).T        \n",
    "    return vec_norm\n",
    "\n",
    "# test this function to get a vector for one movie\n",
    "# Note this is using the title2index but the same could be \n",
    "# done from any other id mapping to index\n",
    "title = 'Mean Girls'\n",
    "idx = title2index[title] # the mapping to matrix index\n",
    "smd[smd.index == idx]\n",
    "movie_toks = tokens[idx] # tokens list also based on this index\n",
    "print(\"Mean Girls movie vector:\")\n",
    "print(movie_vector(W_norm, movie_toks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we can get a vector representation of a movie description, we can use this to create a matrix of all the movies. This will be consructed with the following code, filling each row of the array with the movie vector for that movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9219, 50)\n"
     ]
    }
   ],
   "source": [
    "# create a matrix length of tokens (one set of tokens for each movie)\n",
    "# the width of the matrix is the dimension of the embedding vectors.\n",
    "movie_desc = np.zeros((len(tokens), vector_dim))\n",
    "\n",
    "i = 0\n",
    "# fill in the matrix row by row for each movie tokens\n",
    "# the corresponding index of the arrays will be the same as titles\n",
    "# and ids mapping to indexes\n",
    "for movie_toks in tokens:\n",
    "    # words not found in embedding index will be all-zeros.\n",
    "    # use the normalized word embeddings W_norm\n",
    "    movie_desc[i] = movie_vector(W_norm, movie_toks)\n",
    "    i = i+1\n",
    "\n",
    "# Check the result embedding matrix dimensions\n",
    "print(movie_desc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing Movie Similarities\n",
    "\n",
    "Now that we have a representation of movies as a vector, we can use this to compute similarity to other movies. This will be done with modified code from the GloVe github account.\n",
    "\n",
    "The following function will take in a desired matrix of word embeddings W, the movie embeddings matrix M, the vocab mappings, and the tokens for a desired movie. To use this function, first the tokens for the desired move must be retrieved from the tokens list, access from the index, and the the function can first compute a movie representation, and then find similar movies from the matrix M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try using distance fucntion on movies\n",
    "# M is the embedding matrix of movies\n",
    "def movie2movie_distance(W, M, vocab, ivocab, movie_toks):\n",
    "    N= 10\n",
    "    # this will generate a movie vector from the tokens\n",
    "    for idx, term in enumerate(movie_toks):\n",
    "        if term in vocab:\n",
    "            #print('Word: %s  Position in vocabulary: %i' % (term, vocab[term]))\n",
    "            if idx == 0:\n",
    "                vec_result = np.copy(W[vocab[term], :])\n",
    "            else:\n",
    "                vec_result += W[vocab[term], :] \n",
    "        else:\n",
    "            #print('Word: %s  Out of dictionary!\\n' % term)\n",
    "            continue\n",
    "    \n",
    "    # normalize the movie vector\n",
    "    vec_norm = np.zeros(vec_result.shape)\n",
    "    d = (np.sum(vec_result ** 2,) ** (0.5))\n",
    "    vec_norm = (vec_result.T / d).T\n",
    "\n",
    "    # get the distance between this movie and othe movies\n",
    "    # this is the cosine distance, dot product of normalize vecs\n",
    "    dist = np.dot(M, vec_norm.T)\n",
    "    \n",
    "    a = np.argsort(-dist)[:N]\n",
    "\n",
    "    print(\"\\n                               Word       Cosine distance\\n\")\n",
    "    print(\"---------------------------------------------------------\\n\")\n",
    "    for x in a:\n",
    "        print(\"%35s\\t\\t%f\\n\" % (titles.iloc[x], dist[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                               Word       Cosine distance\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "                         Mean Girls\t\t1.000000\n",
      "\n",
      "                      Deadly Friend\t\t0.954311\n",
      "\n",
      "           'Neath the Arizona Skies\t\t0.949922\n",
      "\n",
      "                        Phantasm II\t\t0.944674\n",
      "\n",
      "                    Another 48 Hrs.\t\t0.943287\n",
      "\n",
      "         House II: The Second Story\t\t0.942317\n",
      "\n",
      "                       The Freshman\t\t0.941801\n",
      "\n",
      "      Hello Mary Lou: Prom Night II\t\t0.940905\n",
      "\n",
      "                  Feeling Minnesota\t\t0.940621\n",
      "\n",
      "                  Crimes of Passion\t\t0.940600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# call this Function with previously generated matrices\n",
    "# get movie tokens from the tokens list\n",
    "title = 'Mean Girls'\n",
    "idx = title2index[title] # the mapping to matrix index\n",
    "movie_toks = tokens[idx] # tokens list also based on this index\n",
    "\n",
    "movie2movie_distance(W_norm, movie_desc, vocab, ivocab, movie_toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a sanity check we left mean girls as the top entry to confirm it is a cosine distance of 1 as would be expected. The other movies in the list are quite strange and it interesting to think about why these movies might seem similar based on content to Mean Girls. Let's inspect the results for another movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                               Word       Cosine distance\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "                      The Godfather\t\t1.000000\n",
      "\n",
      "                         The Family\t\t0.963330\n",
      "\n",
      "                            Sisters\t\t0.958095\n",
      "\n",
      "                          Max Payne\t\t0.953557\n",
      "\n",
      "                   Casa De Mi Padre\t\t0.953418\n",
      "\n",
      "                The Legend of Zorro\t\t0.952327\n",
      "\n",
      "        Once Upon a Time in America\t\t0.951490\n",
      "\n",
      "                  Gangs of New York\t\t0.950990\n",
      "\n",
      "                      Little Odessa\t\t0.949527\n",
      "\n",
      "                    The Deer Hunter\t\t0.949502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# call this Function with previously generated matrices\n",
    "# get movie tokens from the tokens list\n",
    "title = 'The Godfather'\n",
    "idx = title2index[title] # the mapping to matrix index\n",
    "movie_toks = tokens[idx] # tokens list also based on this index\n",
    "\n",
    "movie2movie_distance(W_norm, movie_desc, vocab, ivocab, movie_toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are actually promising, as it identified Gangs of New York as a similar movie, and also other movies that seem they would have similar content. Whether these movies would appeal to the same users interested in The Godfather though is not verifiable at this point, and will be investigated later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency Inverse Document Frequency Representation\n",
    "\n",
    "Another way of representing documents, is with the term frequency inverse document frequency (tfidf). This does not require a representation of words, instead each word in the vocabulary across all documents are represented in a vocabulary vector. For each movie, the weights in the vocabulary vector are calculated as a count of the occurences of the word in that document, and inversely proportional to the occurence of that word in other documents, which will result in a measure of specificty and importance of that word for that document. The result of this is a very sparse, high dimensional vector for each document that spans the entire vocabulary. The tfidf of the movie descriptions will be implemented with a function from python, and it will also incorporate its own tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9219, 11569)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "['based experiences', 'based life', 'based novel', 'based play', 'based real']\n"
     ]
    }
   ],
   "source": [
    "# create the tfidf vectorizer, and output the matrix (sparse)\n",
    "tf = []\n",
    "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 3),min_df=5, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(smd['description'])\n",
    "\n",
    "# shape will show # docs, vocab\n",
    "print(tfidf_matrix.shape)\n",
    "\n",
    "# type will show what kind of matrix results\n",
    "print(type(tfidf_matrix))\n",
    "\n",
    "# sample of features found\n",
    "print(tf.get_feature_names()[1000:1005])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse Representation Methods\n",
    "\n",
    "The resulting tfidf generated from the data is a sparce matrix as show above, and it has a vocabulary of 11569. Note that in this case, each document is represented by a vector of dimension 11569 in length vs 50 dimensions in length from the GloVe representation. Obviously this vector will be much more sparse, and therefore can make use of efficient python functions optimized for sparse matrices. In order to calculate the cosine distance between two movies using this representation, it is possible to use a built in python function that will simply compute the dot product between these two vectors. Note that the full cosine distance would rewuire to also normalize by vector length, however since this is an efficient function we will first assess results using this method.\n",
    "\n",
    "We will use sklearn's linear_kernel instead of cosine_similarities and the output is a numpy array matrix of cosine similarities between each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(9219, 9219)\n"
     ]
    }
   ],
   "source": [
    "# This simple approach can only be applied on the sparse matrix\n",
    "tfidf_sp_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "print(type(tfidf_sp_sim))\n",
    "print(tfidf_sp_sim.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the resulting matrix is a square matrix, with the where the metric  $dist(u=X[i],v=X[j])$  is computed and stored in entry  $ij$. This matrix can next be used to calculate the most similar movies. To do this we will make a function to generate recommendations from this matrix for a desired movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# once given a simlarity matrix, this function will be the same everytime, change inputs\n",
    "def get_recommendations(title, sim_matrix):\n",
    "    idx = title2index[title]\n",
    "    sim_scores = list(enumerate(sim_matrix[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    #sim_scores = sorted(sim_scores, key=lambda x: 1-x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:31]\n",
    "    scores = [score[1] for score in sim_scores]\n",
    "    #scores = [1-score[1] for score in sim_scores]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    top_titles = titles.iloc[movie_indices]\n",
    "    df = pd.DataFrame()\n",
    "    df['titles'] = top_titles\n",
    "    df['scores'] = scores\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse matrix calculation results:\n",
      "                      titles    scores\n",
      "8494              The Family  0.251606\n",
      "994   The Godfather: Part II  0.244506\n",
      "4237      Johnny Dangerously  0.189206\n",
      "3536                    Made  0.182327\n",
      "29            Shanghai Triad  0.143431\n"
     ]
    }
   ],
   "source": [
    "# the results of the calculation on the sparse matrix\n",
    "print(\"Sparse matrix calculation results:\")\n",
    "print(get_recommendations('The Godfather', tfidf_sp_sim).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting that this method also returned the movie \"The Family\" as its top hit, which is the same as the embedding method. However this method actually seems to be a bit better of a suggestion list, since it is recommending the sequel to the godfather, which definitely would be of interest to users who watched The Godfather."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense Calculation Methods\n",
    "\n",
    "In order to compare to the embedding methods, we will change the tfidf to a regular (non-sparse) matrix representation, and test the document similarites using the same cosine function used previoulsy measuring the distance between the movie embedding vectors.\n",
    "\n",
    "To do this first we will create the regular numpy matrix, and the perform the calculation of cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9219, 11569)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Since this is a sparse matrix, create a regular version too\n",
    "# This will let the embedding matrices to come be compared \n",
    "# directly using the same functions\n",
    "tfidf_np = np.asarray(tfidf_matrix.toarray())\n",
    "print(tfidf_np.shape)\n",
    "print(type(tfidf_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take the index of the movie in the tfidf matrix\n",
    "# take in the tfidf matrix\n",
    "# compute the distance between each movie and the desired movie\n",
    "def movie2movie_tfidf(M, movie_index):\n",
    "    N= 10\n",
    "    vec_result = M[movie_index]\n",
    "    \n",
    "    # normalize the movie vector\n",
    "    vec_norm = np.zeros(vec_result.shape)\n",
    "    d = (np.sum(vec_result ** 2,) ** (0.5))\n",
    "    vec_norm = (vec_result.T / d).T\n",
    "\n",
    "    # get the distance between this movie and other movies\n",
    "    # this is the cosine distance, dot product of normalized vecs\n",
    "    dist = np.dot(M, vec_norm.T)\n",
    "    \n",
    "    a = np.argsort(-dist)[:N]\n",
    "\n",
    "    print(\"\\n                               Word       Cosine distance\\n\")\n",
    "    print(\"---------------------------------------------------------\\n\")\n",
    "    for x in a:\n",
    "        print(\"%35s\\t\\t%f\\n\" % (titles.iloc[x], dist[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                               Word       Cosine distance\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "                         Mean Girls\t\t1.000000\n",
      "\n",
      "                         Wild Child\t\t0.174726\n",
      "\n",
      "                      Pitch Perfect\t\t0.158836\n",
      "\n",
      "                          The Craft\t\t0.156621\n",
      "\n",
      "                        Latter Days\t\t0.145837\n",
      "\n",
      "                         The Clique\t\t0.140224\n",
      "\n",
      "                 Death at a Funeral\t\t0.139270\n",
      "\n",
      "                      Fallen Angels\t\t0.136594\n",
      "\n",
      "                      Doc Hollywood\t\t0.135179\n",
      "\n",
      "                  Mrs. Winterbourne\t\t0.132972\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test this function on the movie index of The Godfather\n",
    "title = 'Mean Girls'\n",
    "idx = title2index[title] # the mapping to matrix index\n",
    "\n",
    "movie2movie_tfidf(tfidf_np, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                               Word       Cosine distance\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "                      The Godfather\t\t1.000000\n",
      "\n",
      "                         The Family\t\t0.251606\n",
      "\n",
      "             The Godfather: Part II\t\t0.244506\n",
      "\n",
      "                 Johnny Dangerously\t\t0.189206\n",
      "\n",
      "                               Made\t\t0.182327\n",
      "\n",
      "                     Shanghai Triad\t\t0.143431\n",
      "\n",
      "                  The Tillman Story\t\t0.135222\n",
      "\n",
      "      Elite Squad: The Enemy Within\t\t0.131102\n",
      "\n",
      "                            Thinner\t\t0.126314\n",
      "\n",
      "                           3 Ninjas\t\t0.123779\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test this function on the movie index of The Godfather\n",
    "title = 'The Godfather'\n",
    "idx = title2index[title] # the mapping to matrix index\n",
    "\n",
    "movie2movie_tfidf(tfidf_np, idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is the same as calculated with the sparse kernel calculation. For sanity check The Godfather is included as the top result with a cosine distance of 1. \n",
    "\n",
    "It seems that the tfidf is providing better recommendations for both The Godfather and Mean Girls, than the embedding based on the suggested lists for these movies, however further investigation is required to see how this corresponds to the actual user preferences.\n",
    "\n",
    "In the next section we will investigate one more approach to a content based recommender, incorporating the metadata of the movies. \n",
    "\n",
    "### Metadata Based Representation\n",
    "\n",
    "The metadata recommender will take in metadata keywords and cast and crew metadata, previously processed into the \"soup\" column of the dataset. This will be a list of words, which can once again be tokenized and created into a vector. In this case, we will try the tfidf vector but also just a simple occurence based vector to represent each document. It is possible the tfidf might not make a lot of sense in this case, becuase odds are each word in the metadata will occure only once (ie. a list of keywords will list each word once), and so just indicating the occurence of each word may be enough. \n",
    "\n",
    "First we will proceed with the tfidf method shown previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9219, 7575)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "['adamsandler', 'adamshankman', 'adamshankman adamshankman', 'adamshankman adamshankman adamshankman', 'adamstorke']\n",
      "<class 'numpy.ndarray'>\n",
      "(9219, 9219)\n"
     ]
    }
   ],
   "source": [
    "# This simple approach can only be applied on the sparse matrix\n",
    "# create the tfidf vectorizer, and output the matrix (sparse)\n",
    "meta_tf = []\n",
    "meta_tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 3),min_df=5, stop_words='english')\n",
    "meta_tfidf_matrix = meta_tf.fit_transform(smd['soup'])\n",
    "\n",
    "# shape will show # docs, vocab\n",
    "print(meta_tfidf_matrix.shape)\n",
    "\n",
    "# type will show what kind of matrix results\n",
    "print(type(meta_tfidf_matrix))\n",
    "\n",
    "# sample of features found\n",
    "print(meta_tf.get_feature_names()[100:105])\n",
    "\n",
    "tfidf_meta = linear_kernel(meta_tfidf_matrix, meta_tfidf_matrix)\n",
    "print(type(tfidf_meta))\n",
    "print(tfidf_meta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(9219, 9219)\n"
     ]
    }
   ],
   "source": [
    "tfidf_meta_cos = cosine_similarity(meta_tfidf_matrix, meta_tfidf_matrix)\n",
    "print(type(tfidf_meta_cos))\n",
    "print(tfidf_meta_cos.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the shape of this tfidf vector, it is much smaller than the description based tfidf matrix. Also, it seems the metadata token results look quite strange, but what this is doing is it is taking into account the cast and crew members, as these members may have an impact on the qualifty of the movie produced. The next step will be to get recommendations based on this recommendation and see how they compare. For this, we will use the same function as shown previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Godfather:\n",
      "                             titles    scores\n",
      "3616  Tucker: The Man and His Dream  0.717023\n",
      "994          The Godfather: Part II  0.695543\n",
      "4518             One from the Heart  0.692377\n",
      "3300               Gardens of Stone  0.674118\n",
      "1346                  The Rainmaker  0.655029\n",
      "Mean Girls:\n",
      "                     titles    scores\n",
      "3319        Head Over Heels  0.732575\n",
      "4763          Freaky Friday  0.663749\n",
      "7905  Mr. Popper's Penguins  0.663324\n",
      "6277       Just Like Heaven  0.644200\n",
      "1329       The House of Yes  0.641305\n"
     ]
    }
   ],
   "source": [
    "print(\"The Godfather:\")\n",
    "print(get_recommendations('The Godfather', tfidf_meta).head())\n",
    "print(\"Mean Girls:\")\n",
    "print(get_recommendations('Mean Girls', tfidf_meta).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results also look like quite reasonable suggestions, though they are a bit different than the description based findings. We can assess the results as well with direct count based vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9219, 107377)\n"
     ]
    }
   ],
   "source": [
    "count = CountVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "count_matrix = count.fit_transform(smd['soup'])\n",
    "\n",
    "print(count_matrix.shape)\n",
    "\n",
    "# test two methods of assessing cosine similarity\n",
    "meta_count_cos = cosine_similarity(count_matrix, count_matrix)\n",
    "meta_count_kern = linear_kernel(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9219, 107377)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "107377"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the vocabulary from this model for later use in test\n",
    "tfidf_vocab = count.vocabulary_\n",
    "print(count_matrix.shape)\n",
    "len(tfidf_vocab.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In assessing the results we will use the built in cosine similarity function which normalizes results, as well as the same function as previously used which is the linear kernel to compute the dot product. The results are quite similar but it looks like the kernel similarity is actually producing better results, as it recommends both Godfather Part 2 and Part 3 very close to the top. This looks like the best set of recommendations so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Cosine similarity function: -------\n",
      "                             titles    scores\n",
      "3616  Tucker: The Man and His Dream  0.477455\n",
      "994          The Godfather: Part II  0.456630\n",
      "1346                  The Rainmaker  0.431641\n",
      "3705                The Cotton Club  0.407661\n",
      "4518             One from the Heart  0.406297\n",
      "3300               Gardens of Stone  0.406269\n",
      "1602        The Godfather: Part III  0.375081\n",
      "2998               The Conversation  0.369835\n",
      "5867                    Rumble Fish  0.369835\n",
      "1992          Peggy Sue Got Married  0.366774\n",
      "------ Linear Kernel function (same as previous): ------\n",
      "                             titles  scores\n",
      "994          The Godfather: Part II    21.0\n",
      "1346                  The Rainmaker    18.0\n",
      "1602        The Godfather: Part III    18.0\n",
      "3705                The Cotton Club    17.0\n",
      "981                  Apocalypse Now    16.0\n",
      "3300               Gardens of Stone    16.0\n",
      "1691                  The Outsiders    15.0\n",
      "2998               The Conversation    15.0\n",
      "3616  Tucker: The Man and His Dream    15.0\n",
      "4518             One from the Heart    15.0\n"
     ]
    }
   ],
   "source": [
    "print(\"------ Cosine similarity function: -------\")\n",
    "print(get_recommendations('The Godfather', meta_count_cos).head(10))\n",
    "print(\"------ Linear Kernel function (same as previous): ------\")\n",
    "print(get_recommendations('The Godfather', meta_count_kern).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing User Profiles\n",
    "\n",
    "Now that we have the ability to represent movies as vectors and compute similiarities between movies, we will extend the recommendations to take into account user preferences. For each user we will generate a profile based on the movies they previously liked. This will be done by using the previously generated movie vectors. Then, to provide recommendations, similarity measurements will be done using modified version of the recommendation functions to take in a user profile.\n",
    "\n",
    "User profiles will be constructed based on each of the three previous types of document vectors.\n",
    "\n",
    "### Embedding Method User Profiles\n",
    "\n",
    "The embedding for a user profile can be created from the movie vectors they like in a similar way that the movie vectors were created from the words, by adding all the vectors and normalizing them, equivalent to taking the centroid of these vectors. This method will be applied in the following function which is a slight modification of the movie2movie function shown previously. However first it is required to calculate a vector representation of the user to pass into this function. This will be done with the user_vector function, which is similar to the movie_vector function.\n",
    "\n",
    "The user vector will be created by taking in the matrix of previously computed movie embeddings, and the list of movies the user liked. The list of movies the user liked can be obtained from the ranking dataset for a given user id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# will generate an embedding for a user with the embedding matrix of movies M\n",
    "# wil take in a list of movie names\n",
    "\n",
    "def user_vector(M, movies):\n",
    "    vec_result = np.zeros(M.shape[1])\n",
    "    #print(vec_result.shape)\n",
    "    for idx, movie in enumerate(movies):\n",
    "        # indices is the mapping of movies titles to the index\n",
    "        if movie in title2index:\n",
    "            # this is the position of the movie in the array\n",
    "            idm = title2index[movie]\n",
    "            \n",
    "            # hack solution to account for multiple movies of\n",
    "            # same title --> should be replaced with tmdb id\n",
    "            if type(idm) is not np.int64:\n",
    "                idm = idm.iloc[0]\n",
    "                \n",
    "            if idx == 0:\n",
    "                vec_result = np.copy(M[idm, :])\n",
    "            else:\n",
    "                vec_result += M[idm, :]\n",
    "        else:\n",
    "            print('Movie: %s  Out of dictionary!\\n' % movie)\n",
    "            continue\n",
    "    \n",
    "    vec_norm = np.zeros(vec_result.shape)\n",
    "    d = (np.sum(vec_result ** 2,) ** (0.5))\n",
    "    if d > 0:\n",
    "        vec_norm = (vec_result.T / d).T        \n",
    "    return vec_norm\n",
    "    #return vec_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test this function with an example where a user \n",
    "# liked just The Godfather to compare to previous results\n",
    "user_vec = user_vector(movie_desc, ['The Godfather'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm that this result is comparable to the results generated previously, we will create a function for calculating the user to movie distance, similar to the previously function for movie to movie distance. This function is shown below and it will be used to test the user vector of just The Godfather movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try using distance fucntion on movies\n",
    "# M is the embedding matrix of movies\n",
    "def user2movie_distance(M, vocab, ivocab, usr_prof):\n",
    "    N= 10\n",
    "    \n",
    "    # normalize the movie vector\n",
    "    vec_norm = np.zeros(usr_prof.shape)\n",
    "    d = (np.sum(usr_prof ** 2,) ** (0.5))\n",
    "    vec_norm = (usr_prof.T / d).T\n",
    "\n",
    "    # get the distance between this movie and othe movies\n",
    "    # this is the cosine distance, dot product of normalize vecs\n",
    "    dist = np.dot(M, vec_norm.T)\n",
    "    \n",
    "    a = np.argsort(-dist)[:N]\n",
    "\n",
    "    print(\"\\n                               Word       Cosine distance\\n\")\n",
    "    print(\"---------------------------------------------------------\\n\")\n",
    "    for x in a:\n",
    "        print(\"%35s\\t\\t%f\\n\" % (titles.iloc[x], dist[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                               Word       Cosine distance\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "                      The Godfather\t\t1.000000\n",
      "\n",
      "                         The Family\t\t0.963330\n",
      "\n",
      "                            Sisters\t\t0.958095\n",
      "\n",
      "                          Max Payne\t\t0.953557\n",
      "\n",
      "                   Casa De Mi Padre\t\t0.953418\n",
      "\n",
      "                The Legend of Zorro\t\t0.952327\n",
      "\n",
      "        Once Upon a Time in America\t\t0.951490\n",
      "\n",
      "                  Gangs of New York\t\t0.950990\n",
      "\n",
      "                      Little Odessa\t\t0.949527\n",
      "\n",
      "                    The Deer Hunter\t\t0.949502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test the user_vec\n",
    "user2movie_distance(movie_desc, vocab, ivocab, user_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is therefore working, since it is generating the same values seen previously from direct movie to movie recommendations. Next we shall test on an actual user profile. To use this function, we first need to generate a list of movies that a user liked. This can be done with the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to get a user profile based on liked content\n",
    "def user_liked_movies(userID, ratings):\n",
    "    userRated = ratings[ratings['userId'] == userID]\n",
    "    positiveRatings = userRated[ratings['rating'] > 3]\n",
    "    likedMovies = positiveRatings['movieId']\n",
    "\n",
    "    likedMovie_tmdb = []\n",
    "    likedMovie_title = []\n",
    "    for movieID in likedMovies:\n",
    "        # get the associated tmdb id\n",
    "        if movieID in movieid_map.index:\n",
    "            #print(\"1. movieId -------------------\")\n",
    "            #print(movieID)\n",
    "            tmdb_id = movieid_map.loc[movieID]['id']\n",
    "            #print(\"tmdb_id\")\n",
    "            #print(tmdb_id)\n",
    "            # store the tmdb ids\n",
    "            likedMovie_tmdb.append(tmdb_id)\n",
    "            # map the tmdb id to the movie title\n",
    "            if type(tmdb_id) is not np.float:\n",
    "                tmdb_id = tmdb_id.iloc[0]\n",
    "            \n",
    "            idx = id2index[tmdb_id]\n",
    "            #print(\"idx\")\n",
    "            #print(idx)\n",
    "            if type(idx) is not np.int64:\n",
    "                idx = idx.iloc[0]\n",
    "            \n",
    "            #title = smd['title'][smd.index == idx]\n",
    "            title = titles[idx]\n",
    "            #print(\"title\")\n",
    "            #print(title)\n",
    "            likedMovie_title.append(title)\n",
    "    return likedMovie_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test this function for a random user and see what movies they liked. It iwl be printed out in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Twelve Monkeys', 'Braveheart', 'Apollo 13', 'Star Wars', 'Forrest Gump', 'Jurassic Park', 'Terminator 2: Judgment Day', 'The Silence of the Lambs', 'The Rock', 'That Thing You Do!', 'Raiders of the Lost Ark', 'Return of the Jedi', 'Indiana Jones and the Last Crusade', 'Die Hard 2', 'Mars Attacks!', 'The Fifth Element', 'Batman & Robin', 'Air Force One', 'The Game', 'Armageddon', 'Lethal Weapon 4', 'Lethal Weapon 2', 'The Mask of Zorro', 'Blade', 'Planet of the Apes', 'The Mummy', 'Star Wars: Episode I - The Phantom Menace', 'Austin Powers: The Spy Who Shagged Me', 'American Beauty', 'Sleepy Hollow', 'The Green Mile', 'Close Encounters of the Third Kind', 'Gladiator', 'Mission: Impossible II', 'The Patriot', 'Crouching Tiger, Hidden Dragon', 'Cast Away', 'Minority Report']\n"
     ]
    }
   ],
   "source": [
    "usr_num = 300\n",
    "userRated = ratings[ratings['userId'] == usr_num]\n",
    "positiveRatings = userRated[ratings['rating'] > 3]\n",
    "likedMovies = positiveRatings['movieId']\n",
    "\n",
    "likedMoviesList = user_liked_movies(usr_num, ratings)\n",
    "print(likedMoviesList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite a diverse set of ratings, however lets see how the similarity measures would assess this to produce recommentations. TO do this, we will use the two functions needs to first generate the list of movies, and then next, create a user vector, this will be done in the following function. This user seems to overall like action, horror and scifi and histrocial movies, lets see if any of these are detected in the recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_profile(userID, ratings):\n",
    "    likedMovies = user_liked_movies(userID, ratings)\n",
    "    user_vec = user_vector(movie_desc, likedMovies)\n",
    "    return user_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                               Word       Cosine distance\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "       Once Upon a Time in the West\t\t0.983114\n",
      "\n",
      "                         The Spirit\t\t0.979363\n",
      "\n",
      "                         The Jacket\t\t0.977636\n",
      "\n",
      "                    Nothing to Lose\t\t0.977626\n",
      "\n",
      "Captain America: The Winter Soldier\t\t0.977007\n",
      "\n",
      "                                  9\t\t0.975849\n",
      "\n",
      "    Star Trek II: The Wrath of Khan\t\t0.975212\n",
      "\n",
      "              Phantasm IV: Oblivion\t\t0.975141\n",
      "\n",
      "                          First Kid\t\t0.974670\n",
      "\n",
      "                         ParaNorman\t\t0.974628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the user vector function to generate a profile\n",
    "prof11 = user_profile(usr_num, ratings)\n",
    "\n",
    "# get top movies for a user\n",
    "user2movie_distance(movie_desc, vocab, ivocab, prof11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does seem to have recommended some exiting action based movies for this user. IN particular it is a good sign that it recommended Star Trek, since the user liked Star Wars, this seems like it might be a good idea. Next we can assess the same method of generating recommendations from the metadata vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata User Profiles\n",
    "\n",
    "To generate the metadata based profiles, we will use the same method of first finding the list of movies the user liked, then creating a vector based on these movies. Because the tfidf and the regular count vector performed similarly, from this point for the metadata user profile analysis we will just onctinue with count based for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# will generate an embedding for a user with the count matrix\n",
    "# will take in a list of movie names, and the count matrix\n",
    "\n",
    "def user_vector_meta(M, movies):\n",
    "    vec_result = np.zeros((1, M.shape[1])) # vector will be same length\n",
    "    for idx, movie in enumerate(movies):\n",
    "        # indices is the mapping of movies titles to the index\n",
    "        if movie in title2index:\n",
    "            # this is the position of the movie in the array\n",
    "            idm = title2index[movie]\n",
    "            # hack solution to account for multiple movies of\n",
    "            # same title --> should be replaced with tmdb id\n",
    "            if type(idm) is not np.int64:\n",
    "                idm = idm.iloc[0]\n",
    "                \n",
    "            #if idx == 0:\n",
    "            #    vec_result = np.copy(M[idm, :])                \n",
    "            #else:\n",
    "            vec_result += M[idm, :]\n",
    "        else:\n",
    "            print('Movie: %s  Out of dictionary!\\n' % movie)\n",
    "            continue\n",
    "    \n",
    "    #print(vec_result.shape)\n",
    "    #print(vec_result[0])\n",
    "    #vec_norm = np.zeros(vec_result.shape)\n",
    "    #d = (np.sum(vec_result ** 2,) ** (0.5))\n",
    "    #if d > 0:\n",
    "    #    vec_norm = (vec_result.T / d).T        \n",
    "    return vec_result\n",
    "\n",
    "def user_profile_meta(userID, movie_matrix, ratings):\n",
    "    likedMovies = user_liked_movies(userID, ratings)\n",
    "    user_vec = user_vector_meta(movie_matrix, likedMovies)\n",
    "    return user_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# once given a simlarity matrix, this function will be the same everytime, change inputs\n",
    "def get_user_recommendations(prof, count_matrix):\n",
    "    user_meta_sims = cosine_similarity(count_matrix, prof)\n",
    "    sim_scores = list(enumerate(user_meta_sims))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    #sim_scores = sorted(sim_scores, key=lambda x: 1-x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:31]\n",
    "    scores = [score[1] for score in sim_scores]\n",
    "    #scores = [1-score[1] for score in sim_scores]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    top_titles = titles.iloc[movie_indices]\n",
    "    df = pd.DataFrame()\n",
    "    df['titles'] = top_titles\n",
    "    df['scores'] = scores\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we can test this function on just one movie as the input, and see how the results compare to the movie similarity results. This will be done in the code below. Looking at the results, it is a good sign that it is recommending the Godfather part 2 near the top of the list, the same as shown previously. Next we have an adjusted function to get the user recommednations, that will take in the user profile vector and the count matrix, then calculate the similarities between that vector and each movie using the cosine similarity function, and then output the top results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3616</th>\n",
       "      <td>Tucker: The Man and His Dream</td>\n",
       "      <td>[0.477455260559]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>[0.456629651137]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>The Rainmaker</td>\n",
       "      <td>[0.43164102394]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3705</th>\n",
       "      <td>The Cotton Club</td>\n",
       "      <td>[0.407660967054]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4518</th>\n",
       "      <td>One from the Heart</td>\n",
       "      <td>[0.406296733866]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             titles            scores\n",
       "3616  Tucker: The Man and His Dream  [0.477455260559]\n",
       "994          The Godfather: Part II  [0.456629651137]\n",
       "1346                  The Rainmaker   [0.43164102394]\n",
       "3705                The Cotton Club  [0.407660967054]\n",
       "4518             One from the Heart  [0.406296733866]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test this function with an example where a user \n",
    "# liked just The Godfather to compare to previous results\n",
    "user_vec = user_vector_meta(count_matrix, ['The Godfather'])\n",
    "get_user_recommendations(user_vec, count_matrix).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test this function once again on user number 300 and compare the results to results we got previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>The Lost World: Jurassic Park</td>\n",
       "      <td>[0.370625966193]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>Armageddon</td>\n",
       "      <td>[0.356943476739]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5869</th>\n",
       "      <td>Twilight Zone: The Movie</td>\n",
       "      <td>[0.346949005222]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>Indiana Jones and the Last Crusade</td>\n",
       "      <td>[0.344380646326]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6232</th>\n",
       "      <td>War of the Worlds</td>\n",
       "      <td>[0.341673363712]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>Raiders of the Lost Ark</td>\n",
       "      <td>[0.340651711682]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>Jurassic Park</td>\n",
       "      <td>[0.33946901943]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>The Fifth Element</td>\n",
       "      <td>[0.329456655949]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Star Wars</td>\n",
       "      <td>[0.327395220779]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>Star Wars: Episode I - The Phantom Menace</td>\n",
       "      <td>[0.326242953738]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>Lethal Weapon 4</td>\n",
       "      <td>[0.324961021804]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>Lethal Weapon 2</td>\n",
       "      <td>[0.320809011678]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>Return of the Jedi</td>\n",
       "      <td>[0.312446308709]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2788</th>\n",
       "      <td>Close Encounters of the Third Kind</td>\n",
       "      <td>[0.31016389337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3674</th>\n",
       "      <td>Planet of the Apes</td>\n",
       "      <td>[0.303785575676]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>Planet of the Apes</td>\n",
       "      <td>[0.302834432877]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024</th>\n",
       "      <td>Indiana Jones and the Kingdom of the Crystal S...</td>\n",
       "      <td>[0.300160146696]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6242</th>\n",
       "      <td>The Island</td>\n",
       "      <td>[0.297540370567]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>Indiana Jones and the Temple of Doom</td>\n",
       "      <td>[0.29349220226]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>Terminator 2: Judgment Day</td>\n",
       "      <td>[0.291468118107]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 titles            scores\n",
       "1251                      The Lost World: Jurassic Park  [0.370625966193]\n",
       "1497                                         Armageddon  [0.356943476739]\n",
       "5869                           Twilight Zone: The Movie  [0.346949005222]\n",
       "1062                 Indiana Jones and the Last Crusade  [0.344380646326]\n",
       "6232                                  War of the Worlds  [0.341673363712]\n",
       "972                             Raiders of the Lost Ark  [0.340651711682]\n",
       "427                                       Jurassic Park   [0.33946901943]\n",
       "1241                                  The Fifth Element  [0.329456655949]\n",
       "232                                           Star Wars  [0.327395220779]\n",
       "2120          Star Wars: Episode I - The Phantom Menace  [0.326242953738]\n",
       "1498                                    Lethal Weapon 4  [0.324961021804]\n",
       "1580                                    Lethal Weapon 2  [0.320809011678]\n",
       "983                                  Return of the Jedi  [0.312446308709]\n",
       "2788                 Close Encounters of the Third Kind   [0.31016389337]\n",
       "3674                                 Planet of the Apes  [0.303785575676]\n",
       "2043                                 Planet of the Apes  [0.302834432877]\n",
       "7024  Indiana Jones and the Kingdom of the Crystal S...  [0.300160146696]\n",
       "6242                                         The Island  [0.297540370567]\n",
       "1692               Indiana Jones and the Temple of Doom   [0.29349220226]\n",
       "522                          Terminator 2: Judgment Day  [0.291468118107]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the user vector function to generate a profile for user 300\n",
    "prof11 = user_profile_meta(usr_num, count_matrix, ratings)\n",
    "\n",
    "# get top movies for a user\n",
    "get_user_recommendations(prof11, count_matrix).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the original movies liked by the user were:\n",
    "['Braveheart', 'Apollo 13', 'Star Wars', 'Jurassic Park', 'The Silence of the Lambs', 'Die Hard 2', 'Mars Attacks!', 'Batman & Robin', 'Lethal Weapon 2', 'The Mask of Zorro', 'The Mummy']\n",
    "\n",
    "According to this it actually recommended all the movies the user liked in the top ten. Extedning the list to see what else it recommends, these recommendations all look very reasonable given the previously liked items, and this technique seems to be much more effective than the word embeddings method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering\n",
    "\n",
    "The next approach will be to provide user recommendations entirely based on user ratings for purposes of comparison. This technique is used very commonly and is one of the main approaches to building recommedner systems. It works entirely based on the the ratings different users gavre items and finds patterns in this data with matrix factorization to provide recommendations of movies users have not yet rated. \n",
    "\n",
    "To implement collaborative filtering on this data set, we will use the the data that was loaded and split previously in the data loading section, and use frunctions from the pythonn surprise library to run the collaborative filtering algorithm, \"singular value decomposition\". This will also be evaluated with a built in evaultaion method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "RMSE: 0.9059\n",
      "MAE:  0.6976\n",
      "------------\n",
      "Fold 2\n",
      "RMSE: 0.8873\n",
      "MAE:  0.6835\n",
      "------------\n",
      "Fold 3\n",
      "RMSE: 0.9031\n",
      "MAE:  0.6950\n",
      "------------\n",
      "Fold 4\n",
      "RMSE: 0.8928\n",
      "MAE:  0.6896\n",
      "------------\n",
      "Fold 5\n",
      "RMSE: 0.8921\n",
      "MAE:  0.6871\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 0.8963\n",
      "Mean MAE : 0.6906\n",
      "------------\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CaseInsensitiveDefaultDict(list,\n",
       "                           {'mae': [0.69764777436615044,\n",
       "                             0.68353114042359508,\n",
       "                             0.69495540034901448,\n",
       "                             0.68957784720269488,\n",
       "                             0.68706908980686643],\n",
       "                            'rmse': [0.90591356192194716,\n",
       "                             0.88734077023277758,\n",
       "                             0.90310642584720202,\n",
       "                             0.89284567424961658,\n",
       "                             0.89208394615155329]})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = SVD()\n",
    "evaluate(svd, data, measures=['RMSE', 'MAE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation method is showing the Root Mean Squared error for predictions, which in this case for each fold of the training data is around 0.89, which is a good result. Next we can build a training dataset and use svd to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset = data.build_full_trainset()\n",
    "svd.train(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assess the results for user 300, to see how the model will predict a movie that was produced in the top list of movies with the metadata content recommender. The movie chosen is \"The Green Lantern\" shown in the previous chart to have movie id 7903. The user was predicted to have rated this movie with a 3.9. This is a good rating, so this corresponds nicely with giving this movie as a recommendation based on its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=300, iid=7903, r_ui=3, est=3.8621103104241525, details={'was_impossible': False})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict results for user 300 with movie id 7903\n",
    "svd.predict(300, 7903, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can try this again with one movie that was recommended with the content based recommender. Lets choose the Captain America movie, and see how this method predicts the user would have rated it. As shown in the following code, the id for this movie is: 100402."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>...</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>year</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>keywords</th>\n",
       "      <th>description</th>\n",
       "      <th>cast_size</th>\n",
       "      <th>crew_size</th>\n",
       "      <th>director</th>\n",
       "      <th>soup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8626</th>\n",
       "      <td>8626</td>\n",
       "      <td>23249</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 131295, 'name': 'Captain America Collec...</td>\n",
       "      <td>170000000</td>\n",
       "      <td>[Action, Adventure, Science Fiction]</td>\n",
       "      <td>http://www.captainamericathewintersoldiermovie...</td>\n",
       "      <td>100402</td>\n",
       "      <td>tt1843866</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>5881.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>[chrisevans, samuell.jackson, scarlettjohansson]</td>\n",
       "      <td>[{'gender': 1, 'job': 'Casting', 'department':...</td>\n",
       "      <td>[washingtond.c., futur, shield, marvelcom, sup...</td>\n",
       "      <td>After the cataclysmic events in New York with ...</td>\n",
       "      <td>70</td>\n",
       "      <td>41</td>\n",
       "      <td>[anthonyrusso, anthonyrusso, anthonyrusso]</td>\n",
       "      <td>washingtond.c. futur shield marvelcom superher...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      level_0  index  adult  \\\n",
       "8626     8626  23249  False   \n",
       "\n",
       "                                  belongs_to_collection     budget  \\\n",
       "8626  {'id': 131295, 'name': 'Captain America Collec...  170000000   \n",
       "\n",
       "                                    genres  \\\n",
       "8626  [Action, Adventure, Science Fiction]   \n",
       "\n",
       "                                               homepage      id    imdb_id  \\\n",
       "8626  http://www.captainamericathewintersoldiermovie...  100402  tt1843866   \n",
       "\n",
       "     original_language                        ...                          \\\n",
       "8626                en                        ...                           \n",
       "\n",
       "     vote_count  year                                              cast  \\\n",
       "8626     5881.0  2014  [chrisevans, samuell.jackson, scarlettjohansson]   \n",
       "\n",
       "                                                   crew  \\\n",
       "8626  [{'gender': 1, 'job': 'Casting', 'department':...   \n",
       "\n",
       "                                               keywords  \\\n",
       "8626  [washingtond.c., futur, shield, marvelcom, sup...   \n",
       "\n",
       "                                            description cast_size  crew_size  \\\n",
       "8626  After the cataclysmic events in New York with ...        70         41   \n",
       "\n",
       "                                        director  \\\n",
       "8626  [anthonyrusso, anthonyrusso, anthonyrusso]   \n",
       "\n",
       "                                                   soup  \n",
       "8626  washingtond.c. futur shield marvelcom superher...  \n",
       "\n",
       "[1 rows x 35 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smd[smd['title']==\"Captain America: The Winter Soldier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=300, iid=100402, r_ui=3, est=3.8621103104241525, details={'was_impossible': False})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict results for user 300 with movie id 100402\n",
    "svd.predict(300, 100402, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This movie was once again predicted to be rated quite highly, with a rating of 3.9 again, for this user so this is a good sign that even the embedding method can provide some decent recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Method\n",
    "\n",
    "Now we will assess a way to incorporate both the content based recommendations and the user ratings in predictions. There are many ways this could be applied. Often recommender systems incorporate many different features. However for the purposes of this evaulation, we will focus on one method of combining these two approaches: providing a user recommendations based on a specific movie that have selected, and their preferences. This means that the movie similarities will be used in identifying a list of movies similar to one a user selected, and then the collaborative filtering predictions will be used to select movies the user would like the most out of that list. This can be seen in the following code for a hybrid recommender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This will take in the user id and the seelcted title\n",
    "def hybrid(userId, title):\n",
    "    idx = title2index[title]\n",
    "    tmdbId = id_map.loc[title]['id']\n",
    "    movie_id = id_map.loc[title]['movieId']\n",
    "    \n",
    "    # find similar movies to the given title\n",
    "    sim_scores = list(enumerate(meta_count_cos[int(idx)]))\n",
    "    #print(sim_scores)\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:26]\n",
    "    #print(sim_scores)\n",
    "    \n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    \n",
    "    # use the svd predictions to get the top predictions\n",
    "    #movies = smd.iloc[movie_indices][['title', 'vote_count', 'vote_average', 'year', 'id']]\n",
    "    movies = smd.iloc[movie_indices][['title', 'id']]\n",
    "    #print(movies)\n",
    "    \n",
    "    movies['est'] = movies['id'].apply(lambda x: svd.predict(userId, tmdb_map.loc[x]['movieId']).est)\n",
    "    movies = movies.sort_values('est', ascending=False)\n",
    "    return movies.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>est</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>278</td>\n",
       "      <td>4.891969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>The Conversation</td>\n",
       "      <td>592</td>\n",
       "      <td>4.411174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>240</td>\n",
       "      <td>4.382663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>Midnight Express</td>\n",
       "      <td>11327</td>\n",
       "      <td>4.381289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>GoodFellas</td>\n",
       "      <td>769</td>\n",
       "      <td>4.375181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>Apocalypse Now</td>\n",
       "      <td>28</td>\n",
       "      <td>4.122711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>The Paradine Case</td>\n",
       "      <td>31667</td>\n",
       "      <td>3.991149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Feast of July</td>\n",
       "      <td>259209</td>\n",
       "      <td>3.966451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3300</th>\n",
       "      <td>Gardens of Stone</td>\n",
       "      <td>28368</td>\n",
       "      <td>3.869151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>Looking for Richard</td>\n",
       "      <td>42314</td>\n",
       "      <td>3.852843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title      id       est\n",
       "284   The Shawshank Redemption     278  4.891969\n",
       "2998          The Conversation     592  4.411174\n",
       "994     The Godfather: Part II     240  4.382663\n",
       "2808          Midnight Express   11327  4.381289\n",
       "986                 GoodFellas     769  4.375181\n",
       "981             Apocalypse Now      28  4.122711\n",
       "1765         The Paradine Case   31667  3.991149\n",
       "146              Feast of July  259209  3.966451\n",
       "3300          Gardens of Stone   28368  3.869151\n",
       "868        Looking for Richard   42314  3.852843"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test this function for user 300, with movie \"The Godfather\"\n",
    "hybrid(300, 'The Godfather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this list of recommendations is very different from the list seen previoulsy for this user, becaus they selected they wanted movies similar to The Godfather. The result of this is alist consisting of movies similar to The Godfather, ranked based on the predicted rating that user would have given it. It can be seen the top movies in this list are predicted to be rated wuite highly by the user, probably because these are overall well like popular movies, and also seem to fit within the genre of movies this user previously like. Now lets see how this method handles predictions for this user based on the selected movie \"Mean Girls, which is a bit different in style of genre to the types of movies this user previoulsy liked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>est</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>The Breakfast Club</td>\n",
       "      <td>2108</td>\n",
       "      <td>4.134750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7332</th>\n",
       "      <td>Ghosts of Girlfriends Past</td>\n",
       "      <td>12556</td>\n",
       "      <td>4.033310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6959</th>\n",
       "      <td>The Spiderwick Chronicles</td>\n",
       "      <td>8204</td>\n",
       "      <td>4.001881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7377</th>\n",
       "      <td>I Love You, Beth Cooper</td>\n",
       "      <td>19840</td>\n",
       "      <td>3.975022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5163</th>\n",
       "      <td>Just One of the Guys</td>\n",
       "      <td>24548</td>\n",
       "      <td>3.946458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>Dazed and Confused</td>\n",
       "      <td>9571</td>\n",
       "      <td>3.916099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7084</th>\n",
       "      <td>The Sisterhood of the Traveling Pants 2</td>\n",
       "      <td>10188</td>\n",
       "      <td>3.910710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7436</th>\n",
       "      <td>Reckless</td>\n",
       "      <td>38702</td>\n",
       "      <td>3.902787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5092</th>\n",
       "      <td>Lord Love a Duck</td>\n",
       "      <td>52867</td>\n",
       "      <td>3.900065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6698</th>\n",
       "      <td>It's a Boy Girl Thing</td>\n",
       "      <td>37725</td>\n",
       "      <td>3.898058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title     id       est\n",
       "1547                       The Breakfast Club   2108  4.134750\n",
       "7332               Ghosts of Girlfriends Past  12556  4.033310\n",
       "6959                The Spiderwick Chronicles   8204  4.001881\n",
       "7377                  I Love You, Beth Cooper  19840  3.975022\n",
       "5163                     Just One of the Guys  24548  3.946458\n",
       "390                        Dazed and Confused   9571  3.916099\n",
       "7084  The Sisterhood of the Traveling Pants 2  10188  3.910710\n",
       "7436                                 Reckless  38702  3.902787\n",
       "5092                         Lord Love a Duck  52867  3.900065\n",
       "6698                    It's a Boy Girl Thing  37725  3.898058"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test this function for user 300, with movie \"The Godfather\"\n",
    "hybrid(300, 'Mean Girls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the top rated movies predicted in this list are lower than the previous list, where the top movie here predicts the user would rate it at 4.3 vs 4.9 in the list previously for Shawshank Redemption. It is clear that the recommendation at the top of the list would have been suggested because it is a classic well liked movie within this genre. Other movie suggested, such as the Spiderwick Chronicles, as more action based teen targeted movies, so it is still picking up some of the user's preference towards more action style movies. It seems like a reasonable list given the inputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Results\n",
    "\n",
    "Next we will try to get some quantitative measure of success of the different recommendation approaches. To do this we will assess the precision, recall, and F score. We will focus on the best recommender prodcued through assessment of the heuristic evaluations of movie lists shown in the previous section. The best recommender was the tfidf metadata recommender, and so now we will evaulate it with some standard metrics used in the literature for comparison to previous research.\n",
    "\n",
    "To calculate the precision, we need to calculate the number of items in the top ten that were relevant to the user. Relevant here means items the user had positively rated. To do this we need to access the movieIds of the recommended movies, and look up in the ratings dataset the rating that the user gave that movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         titles            scores\n",
      "1251              The Lost World: Jurassic Park  [0.370625966193]\n",
      "1497                                 Armageddon  [0.356943476739]\n",
      "5869                   Twilight Zone: The Movie  [0.346949005222]\n",
      "1062         Indiana Jones and the Last Crusade  [0.344380646326]\n",
      "6232                          War of the Worlds  [0.341673363712]\n",
      "972                     Raiders of the Lost Ark  [0.340651711682]\n",
      "427                               Jurassic Park   [0.33946901943]\n",
      "1241                          The Fifth Element  [0.329456655949]\n",
      "232                                   Star Wars  [0.327395220779]\n",
      "2120  Star Wars: Episode I - The Phantom Menace  [0.326242953738]\n"
     ]
    }
   ],
   "source": [
    "# get list of recommended movies for user 300\n",
    "recommendations = get_user_recommendations(prof11, count_matrix).head(10)\n",
    "print(recommendations)\n",
    "\n",
    "# Get a list of the tmbd ids from the recommended movies\n",
    "rec_tmdb = ids[recommendations.index]\n",
    "# get a list of the movie Ids from the list\n",
    "rec_movieId = tmdb_map.loc[rec_tmdb]['movieId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the recommended movie Ids to look up ratings\n",
    "user_rated_movies = ratings[ratings['userId'] == 300]\n",
    "user_positive_movies = user_rated_movies[user_rated_movies['rating'] > 3]\n",
    "\n",
    "# list of movie Ids:\n",
    "positive_movieIds = [mid for mid in user_positive_movies['movieId']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, to test the results of the model, we will split the data into a train and test set. This will assess the effectiveness of the model on unseen data. This is done in the following code using a random sample of ratings from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try splitting the ratings dataset into test and train\n",
    "ratings_train= ratings.sample(frac=0.8,random_state=200)\n",
    "ratings_test= ratings.drop(ratings_train.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will use the method shown previsouly to access the user ratings from the train and test set, to create teh user profile from the training set, and then produce rankings from the test set. The tricky part to note in this implementation, is that the count matrix generated from the tfidf vectorizer needs to be created just out of data in the test set. In order to do this, the tfidf vectorizer is once again applied. The important thing to note is that it is taking in the full vocabulary previously generated, to result in a matrix of the same dimensions, to be able to get distance measure from teh user profile vector.\n",
    "\n",
    "After this is done, the recommendations are found as usual from this matrix, and the number of relevant items produced in the recommendations is counted up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to calculate the number of relevant items\n",
    "def user_rel_items(user_id, ratings_train, ratings_test):\n",
    "    # need to generate user profile\n",
    "    profile = user_profile_meta(user_id, count_matrix, ratings_train)\n",
    "    \n",
    "    # get out the movie ids\n",
    "    movieIds_test = [mid for mid in ratings_test['movieId']]\n",
    "\n",
    "    # get the corresponding tmdb ids, 'id' in smd\n",
    "    tmdb_test = movieid_map.loc[movieIds_test]['id']\n",
    "    tmdb_test_list = [tmdb for tmdb in tmdb_test]\n",
    "    smd_test_idx = smd['id'].isin(tmdb_test_list)\n",
    "\n",
    "    # try to access smd at same indice of test\n",
    "    smd_test = smd[smd_test_idx]\n",
    "    \n",
    "    # need to only apply to indecies of smd in test\n",
    "    count_test = CountVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english', vocabulary=tfidf_vocab)\n",
    "    count_matrix_test = count_test.fit_transform(smd_test['soup'])\n",
    "    \n",
    "    # need to get recommendations from user profile\n",
    "    recommendations = get_user_recommendations(profile, count_matrix_test).head(10)\n",
    "    \n",
    "    # get the ids of the movies:\n",
    "    # Get a list of the tmbd ids from the recommended movies\n",
    "    rec_tmdb = ids[recommendations.index]\n",
    "    # get a list of the movie Ids from the list\n",
    "    rec_movieId = tmdb_map.loc[rec_tmdb]['movieId']\n",
    "    \n",
    "    # Get the list of movies the user rated positively in the test set\n",
    "    user_rated_movies = ratings_test[ratings_test['userId'] == user_id]\n",
    "    user_positive_movies = user_rated_movies[user_rated_movies['rating'] > 3]\n",
    "    positive_movieIds = [mid for mid in user_positive_movies['movieId']]\n",
    "    \n",
    "    # Get the positive rated movies that were recommended:\n",
    "    success_count = 0\n",
    "    for movieId in rec_movieId:\n",
    "        if movieId in positive_movieIds:\n",
    "            success_count = success_count +1\n",
    "    \n",
    "    return success_count\n",
    "\n",
    "# test the function for user 300\n",
    "user_rel_items(300, ratings_train, ratings_test)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next sections of code, the precision recall and F measure functions will be defined. Also, there is a helper function for the recall that will return the total number of positive ratings in the test set for a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total positive ratings for user 300\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Next we can use this result to calculate precision, recall and F score\n",
    "# we are keeping the top k, as 10. This function will be used \n",
    "# to calculate the overall precision across many users\n",
    "\n",
    "def precision(tot_rel, num_users):\n",
    "    k = 10\n",
    "    prec = tot_rel/(num_users*k)\n",
    "    return prec\n",
    "\n",
    "prec300 = precision(user_rel_items(300, ratings_train, ratings_test), 1)\n",
    "\n",
    "# this function will return the total number of positive ratings for a user\n",
    "# this will be needed to calculate the recall\n",
    "\n",
    "def user_pos_tot(user_id, ratings_test):\n",
    "    # Get the list of movies the user rated positively\n",
    "    user_rated_movies = ratings_test[ratings_test['userId'] == user_id]\n",
    "    user_positive_movies = user_rated_movies[user_rated_movies['rating'] > 3]\n",
    "    positive_movieIds = [mid for mid in user_positive_movies['movieId']]\n",
    "    return len(positive_movieIds)\n",
    "\n",
    "print(\"total positive ratings for user 300\")\n",
    "print(user_pos_tot(300, ratings_test))\n",
    "\n",
    "# Recall is calculated as relevant found in top k/total relevant\n",
    "# To use this function, first calculate the total relvant\n",
    "# results, then calculate the total possible positive ratings\n",
    "\n",
    "def recall(tot_rel, tot_pos):\n",
    "    \n",
    "    \n",
    "    if tot_pos == 0:\n",
    "        rec = 1\n",
    "    else:\n",
    "        rec = tot_rel/tot_pos\n",
    "        \n",
    "    return rec\n",
    "\n",
    "rec300 = recall(user_rel_items(300, ratings_train, ratings_test), user_pos_tot(300, ratings_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can use the recall and precision to compute the F score. The result is calculated for user 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def F_score(prec, rec):\n",
    "    if prec+rec >0:\n",
    "        F1 = 2*prec*rec/(prec+rec)\n",
    "    else:\n",
    "        F1 = 0\n",
    "    return F1\n",
    "\n",
    "F_score(prec300, rec300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly this method does not perform well on unseen data. To be thorough we will assess the precision and recall for all users, and then once again compute the F1 measure.  In the next section of code we will extract all the user ids in the rating test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671\n"
     ]
    }
   ],
   "source": [
    "# use these functions to calculate the scores across all users\n",
    "# first get a list of all user ids in the ratings\n",
    "all_users = [uid for uid in ratings_test['userId']]\n",
    "all_users = set(all_users)\n",
    "num_users = len(all_users)\n",
    "print(len(all_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to calculate the total recall and precision across all users, we will count up the total number of predictions in the top ten that were relevant predictions, which is done in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rel_items = 0\n",
    "tot_pos = 0\n",
    "for user_id in all_users:\n",
    "    rel_items = rel_items + user_rel_items(user_id, ratings_train, ratings_test)\n",
    "    tot_pos = tot_pos + user_pos_tot(user_id, ratings_test)\n",
    "    #print(rel_items, user_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the total number of possible positive ratings per user, and the total number of relevant results returned to each user, we can use this to calculate overall precision and recall scores. This precision and recall scores can then be used to calculate the overall F measure across all users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.005216095380029807\n",
      "recall:  0.0028212155408673225\n",
      "F1:  0.003661853944339821\n"
     ]
    }
   ],
   "source": [
    "p = precision(rel_items, num_users)\n",
    "r = recall(rel_items, tot_pos)\n",
    "F1 = F_score(p, r)\n",
    "print(\"precision: \", p)\n",
    "print(\"recall: \", r)\n",
    "print(\"F1: \", F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers are much lower than seen in the literature. This is quite extreme, and reasons for this may be due to the method of calculating the evaluation scores. Since many users had ratings for movies within a certain rainge of similarity, perhaps instead of doing only the top ten, it would make more sense to see if the relevant movies could be found within a certain distance of similarity measure as the cutoff.\n",
    "\n",
    "To analyze thse results a bit more, we will produce scores in the hypothetical situation that in the recall the maximum number of relevant items were returned in the top ten. i.e for each user the top ten was all completely correct. In this case we can see an upper bound for what the maxium highest recall score could be, and also see how this impacts the maximum possible F score possible at this level of k (k is the number of items in the reccomendations list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.005216095380029807\n",
      "maximum possible recall:  0.5408673222634209\n",
      "F1 with max recall:  0.010332544258684496\n"
     ]
    }
   ],
   "source": [
    "max_rel = 10*num_users\n",
    "\n",
    "p = precision(rel_items, num_users)\n",
    "r = recall(max_rel, tot_pos)\n",
    "F1 = F_score(p, r)\n",
    "print(\"precision: \", p)\n",
    "print(\"maximum possible recall: \", r)\n",
    "print(\"F1 with max recall: \", F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that with this perspective in mind of what the maximum acheivable recall score could be, this puts the results into a bit better perspective. \n",
    "\n",
    "Next, we will try one more approach of evaluating with this method. Instead of calculating overall relevant predictions, we will calculate the precision and recall individually for each user, and then take the average of this to produce final scores. These can then be used to calculate the overall average F measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avergae precision:  0.005216095380029809\n",
      "avergae recall:  0.0262367939222\n",
      "average F1:  0.008702133419245498\n"
     ]
    }
   ],
   "source": [
    "# calculate average precision and recalls\n",
    "rec = 0\n",
    "prec = 0\n",
    "for user_id in all_users:\n",
    "    rel_items = user_rel_items(user_id, ratings_train, ratings_test)\n",
    "    tot_pos = user_pos_tot(user_id, ratings_test)\n",
    "    prec = prec + precision(rel_items, 1)\n",
    "    rec = rec + recall(rel_items, tot_pos)\n",
    "    \n",
    "avg_prec = prec/num_users\n",
    "avg_rec = rec/num_users\n",
    "F1_avg = F_score(avg_prec, avg_rec)\n",
    "print(\"avergae precision: \", avg_prec)\n",
    "print(\"avergae recall: \", avg_rec)\n",
    "print(\"average F1: \", F1_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this way of evaluatiing results could offset some user that had rated many movies and therefore resulted in extremely low recalls, for example if they had one prediction in the top k, out of 1000 possible correct answers. Most users only rated on average 20 movies, so adding this large numbers of ratings to the sum for total positives could skew the results, but will have less of an effect when it is just effect the result of one user and then being averaged out.\n",
    "\n",
    "Finally we can repeat the same procedure shown previously to see in this case how the maximium possible results would be. This will be shown in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate average precision and recalls\n",
    "rec_max = 0\n",
    "for user_id in all_users:\n",
    "    tot_pos = user_pos_tot(user_id, ratings_test)\n",
    "    # testing every recall assuming 10/10 relevant items\n",
    "    # or all the positive items the user rated:\n",
    "    if 10 < tot_pos:\n",
    "        rec_max = rec_max + recall(10, tot_pos)\n",
    "    else:\n",
    "        rec_max= rec_max + recall(tot_pos, tot_pos)\n",
    "    \n",
    "avg_rec_max = rec_max/num_users\n",
    "F1_avg = F_score(avg_prec, avg_rec_max)\n",
    "print(\"Average max recall: \", avg_rec_max)\n",
    "print(\"Average F1 with max recall: \", F1_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that with the method of calculating the score that max recall is quite high. However the overall highest possible F1 measure is still similar as before within the same order of magnitude. This means that it is probably an effect of the dataset and these evaluation techniques that is contributing to the low results. While these scores could be used to compare model to model, it would be worthwhile to investigate further approaches to measure success of content based recommenders for future research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified F measure Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare to previous sstudies, a modified version of the F measure was also calculuated. This modified function shown in the code below evalutes the top k scores only out of items each user rated. Therefore instead of in the testing having to predict out of all items in the test set, the predictions are only done out of the items the user rated, so there will be much fewer items to assess. On average users only rated 20 items so it makes sense that the results will be much higher when calculated this way. The same method as before was applied and the results are shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tot_rel(user_id, movie_matrix, ratings_train, ratings_test):\n",
    "    profile = user_profile_meta(user_id, movie_matrix, ratings_train)\n",
    "\n",
    "    # Get the list of movies the user rated positively in the test set\n",
    "    user_rated_movies = ratings_test[ratings_test['userId'] == user_id]\n",
    "\n",
    "    # get out the test movie ids\n",
    "    movieIds_test = [mid for mid in user_rated_movies['movieId']]\n",
    "\n",
    "    # get the corresponding tmdb ids, 'id' in smd to user's test movies\n",
    "    tmdb_test = movieid_map.loc[movieIds_test]['id']\n",
    "    tmdb_test_list = [tmdb for tmdb in tmdb_test]\n",
    "    smd_test_idx = smd['id'].isin(tmdb_test_list)\n",
    "    smd_test = smd[smd_test_idx]\n",
    "    # will be number of items in test the user rated\n",
    "    if len(movieIds_test)==0:\n",
    "        print(\"no items in test\")\n",
    "\n",
    "    \n",
    "    user_meta_sims = cosine_similarity(movie_matrix, profile)\n",
    "    sim_scores = list(enumerate(user_meta_sims))\n",
    "    user_rated_scores = []\n",
    "    for idx in smd_test.index:\n",
    "        #print(sim_scores[idx])\n",
    "        user_rated_scores.append(sim_scores[idx])\n",
    "\n",
    "    user_rated_scores_sort = sorted(user_rated_scores, key=lambda x: x[1], reverse=True)\n",
    "    scores = [score[1] for score in user_rated_scores_sort]\n",
    "    movie_indices = [i[0] for i in user_rated_scores_sort]\n",
    "\n",
    "    # get the ids of the movies:\n",
    "    # Get a list of the tmbd ids from the recommended movies\n",
    "    rec_tmdb = ids[movie_indices]\n",
    "    # get a list of the movie Ids from the list\n",
    "    rec_movieId = tmdb_map.loc[rec_tmdb]['movieId']\n",
    "\n",
    "    # Get the list of movies the user rated positively in the test set\n",
    "    user_rated_movies = ratings_test[ratings_test['userId'] == user_id]\n",
    "    user_positive_movies = user_rated_movies[user_rated_movies['rating'] > 3]\n",
    "    positive_movieIds = [mid for mid in user_positive_movies['movieId']]\n",
    "\n",
    "    success_count = 0\n",
    "    topk = 10\n",
    "    for movieId in rec_movieId:\n",
    "        if topk == 0:\n",
    "            #print(\"top 10 reached\")\n",
    "            break\n",
    "        topk= topk-1\n",
    "        if movieId in positive_movieIds:\n",
    "            success_count = success_count +1\n",
    "    return success_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 73\n",
    "tot_rel(user_id, count_matrix, ratings_train, ratings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average precision and recalls\n",
    "rec = 0\n",
    "prec = 0\n",
    "rel = 0\n",
    "for user_id in all_users:\n",
    "    rel_items = tot_rel(user_id, count_matrix, ratings_train, ratings_test)\n",
    "    rel = rel+rel_items\n",
    "    #print(user_id, rel)\n",
    "    tot_pos = user_pos_tot(user_id, ratings_test)\n",
    "    prec = prec + precision(rel_items, 1)\n",
    "    rec = rec + recall(rel_items, tot_pos)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avergae precision:  0.5709388971684057\n",
      "avergae recall:  0.6562348688608758\n",
      "average F1:  0.6106225910014146\n"
     ]
    }
   ],
   "source": [
    "avg_prec = prec/num_users\n",
    "avg_rec = rec/num_users\n",
    "F1_avg = F_score(avg_prec, avg_rec)\n",
    "print(\"avergae precision: \", avg_prec)\n",
    "print(\"avergae recall: \", avg_rec)\n",
    "print(\"average F1: \", F1_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 73\n",
    "tot_rel(user_id, meta_tfidf_matrix, ratings_train, ratings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate average precision and recalls\n",
    "rec = 0\n",
    "prec = 0\n",
    "rel = 0\n",
    "for user_id in all_users:\n",
    "    rel_items = tot_rel(user_id, meta_tfidf_matrix, ratings_train, ratings_test)\n",
    "    rel = rel+rel_items\n",
    "    #print(user_id, rel)\n",
    "    tot_pos = user_pos_tot(user_id, ratings_test)\n",
    "    prec = prec + precision(rel_items, 1)\n",
    "    rec = rec + recall(rel_items, tot_pos)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avergae precision:  0.5839046199701937\n",
      "avergae recall:  0.6591773210468267\n",
      "average F1:  0.6192619656656209\n"
     ]
    }
   ],
   "source": [
    "avg_prec = prec/num_users\n",
    "avg_rec = rec/num_users\n",
    "F1_avg = F_score(avg_prec, avg_rec)\n",
    "print(\"avergae precision: \", avg_prec)\n",
    "print(\"avergae recall: \", avg_rec)\n",
    "print(\"average F1: \", F1_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are much more comparable to the results in the reference study research paper! Actually, comparing the top 10 F measure values, these values computed using the tfidf actually outperform all the methods used in the past study. It must be taken into account however that the dimensions of these tfidf vectors for document representation are around 7000, vs the length 300 and 500 vectors used in the study. However, it should be noted that the study did not find significant improvements with the larger vector sizees (ie. 500 vs 300). Actually counter-intuitively the 300 sized document vecotr actually often outperformed the 500 dimension vector. Further investigation is require to assess the impact the length of the document representation vector has on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "To fully evaulate recommenders it would be advisable to consider additional method of evaluation. The results of testing different recommenders showed that the lists of movies produced did heuristically seem like valid lists of recommendations. The best method shown was the metadata tdidf recommender. This recommender was then evaluated quantitatively, were similar but slightly higher than the values seen in the reference study in the literature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
